{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ke-t5_base.ipynb","provenance":[{"file_id":"1MBUTzWeSShFEn3gaSdRgOcSH2P5jxLfc","timestamp":1637580626494}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2513be19c6334d38bf82004a8568c27d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7b8275241ec8496e97ec0d73a406a727","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8100d85f82224e7380a08b60c90095c7","IPY_MODEL_41095125a446427b8150b4c62098c13e","IPY_MODEL_88f6187f0e8646a68203a2044580ee64"]}},"7b8275241ec8496e97ec0d73a406a727":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8100d85f82224e7380a08b60c90095c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cdf8dcde4ee34e559859143cc021ce89","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb833200f357407da6234e0b2b92959e"}},"41095125a446427b8150b4c62098c13e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_beb3290c8a684a95aa677960c18366e7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":599,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":599,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_629b0081677142dab8edfc28d115c2f8"}},"88f6187f0e8646a68203a2044580ee64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f188d277fc824b71830f7e223ad5d20e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 599/599 [00:00&lt;00:00, 16.3kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5073655130b6460996fa1bc9cee52497"}},"cdf8dcde4ee34e559859143cc021ce89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fb833200f357407da6234e0b2b92959e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"beb3290c8a684a95aa677960c18366e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"629b0081677142dab8edfc28d115c2f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f188d277fc824b71830f7e223ad5d20e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5073655130b6460996fa1bc9cee52497":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9dc38df5eaa40a7b9d1426cb8d96d7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1081bfafb3bf47b2bc65885bfb83b833","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_29066060e9b441a3ae5a3ed278a89faa","IPY_MODEL_91c699821f3941c68267d355a9170d48","IPY_MODEL_4728e767509945b7b15e9282012ebf1d"]}},"1081bfafb3bf47b2bc65885bfb83b833":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29066060e9b441a3ae5a3ed278a89faa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fa4d348928fd4667b01a18039b205c47","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe98a623dade43d0a68e8b94f7497614"}},"91c699821f3941c68267d355a9170d48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b02996421b994c17ad530c0067e2cbd1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":990048016,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":990048016,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fd87c088d1a04a10b1354d6d9bd87270"}},"4728e767509945b7b15e9282012ebf1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b71e815122794f959d191c2f3263cc02","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 944M/944M [00:20&lt;00:00, 46.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d7430df58e441368d1d203d5493bb29"}},"fa4d348928fd4667b01a18039b205c47":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fe98a623dade43d0a68e8b94f7497614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b02996421b994c17ad530c0067e2cbd1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fd87c088d1a04a10b1354d6d9bd87270":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b71e815122794f959d191c2f3263cc02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5d7430df58e441368d1d203d5493bb29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b1c6eceb5374f228e4cc2e7d1c8ea3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fad790e5add94d579391a0c7e9058ee1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_306bcdd2d4164f668e34d5cab0aea56d","IPY_MODEL_b66496c164af4e1ab076533353fb224c","IPY_MODEL_3086fa9b64684cb4a6fe31537beedc79"]}},"fad790e5add94d579391a0c7e9058ee1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"306bcdd2d4164f668e34d5cab0aea56d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_23cf5db65cee4949ba3e0954c0978ffd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b7c5137eb2e7475ea5ae51869821a0ff"}},"b66496c164af4e1ab076533353fb224c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_78c72d5e94354d22a901bbaa6699928d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1466734,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1466734,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d09a0f07a7d415483fd7e8a2acb2e8b"}},"3086fa9b64684cb4a6fe31537beedc79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_340a8455dcdf455e9b94a392cad06f8c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.40M/1.40M [00:00&lt;00:00, 2.92MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_341211f640664e55a119e75c6b105a34"}},"23cf5db65cee4949ba3e0954c0978ffd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b7c5137eb2e7475ea5ae51869821a0ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78c72d5e94354d22a901bbaa6699928d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5d09a0f07a7d415483fd7e8a2acb2e8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"340a8455dcdf455e9b94a392cad06f8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"341211f640664e55a119e75c6b105a34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f864586d84d4373a5589e9a8312fd42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_34928679beca4ac49823ba4404b3a60f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e17df36f30b04da9874a90478e4a0fec","IPY_MODEL_2c0a2119043b45deb3f0beb2945388ce","IPY_MODEL_ed2eebf3ed494f2ab4e73d79d1cf027b"]}},"34928679beca4ac49823ba4404b3a60f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e17df36f30b04da9874a90478e4a0fec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_edc19f0791944624aed879d7e146be78","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7449ba4d0e3e449f968dcd159a508fce"}},"2c0a2119043b45deb3f0beb2945388ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d7e9b9b71114411c8ecc87bede7ac238","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1786,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1786,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6d68d568c4c44de8accf8002782fabc1"}},"ed2eebf3ed494f2ab4e73d79d1cf027b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_622da2aae1c84f5fa53a9f9f7c41ef73","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.74k/1.74k [00:00&lt;00:00, 49.6kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c77dc3ecb51d445b9efd7c3f3f6e8a6d"}},"edc19f0791944624aed879d7e146be78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7449ba4d0e3e449f968dcd159a508fce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7e9b9b71114411c8ecc87bede7ac238":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6d68d568c4c44de8accf8002782fabc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"622da2aae1c84f5fa53a9f9f7c41ef73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c77dc3ecb51d445b9efd7c3f3f6e8a6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ed37c8611364d35914b2e4061734ce4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7697bf98fbe04cef8ffe15b32a050810","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8d01b27deb5d4168b9f2ec32828e98cf","IPY_MODEL_7553afa8fc184b368a6565d09587f67e","IPY_MODEL_b2a2e5253d3d42d08ab269fb49f3c61e"]}},"7697bf98fbe04cef8ffe15b32a050810":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d01b27deb5d4168b9f2ec32828e98cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fba1c0a8509647fa8a7b48976bdf39d6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c401f7ee828e4dc399eae6d268875506"}},"7553afa8fc184b368a6565d09587f67e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_668d822c7e194fb68b8d6e74ee5086f1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1964,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1964,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f057f8be8a9b4df781845221a17691d6"}},"b2a2e5253d3d42d08ab269fb49f3c61e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ba43630d133f4b72bcf371bf7893f257","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.92k/1.92k [00:00&lt;00:00, 51.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7388e556b6464ae6a396761f849f034f"}},"fba1c0a8509647fa8a7b48976bdf39d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c401f7ee828e4dc399eae6d268875506":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"668d822c7e194fb68b8d6e74ee5086f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f057f8be8a9b4df781845221a17691d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba43630d133f4b72bcf371bf7893f257":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7388e556b6464ae6a396761f849f034f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"23RcYKGZFSro"},"source":["참고 url : https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WeqjAR4v1Lag","executionInfo":{"status":"ok","timestamp":1638312458419,"user_tz":-540,"elapsed":27797,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"a88f8152-dcb1-45d8-ef83-81c30756aad2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"UdvHsOH9kIOv","executionInfo":{"status":"ok","timestamp":1638312463712,"user_tz":-540,"elapsed":5297,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["import gc\n","import torch\n","gc.collect()\n","torch.cuda.empty_cache()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"JR-heIHg7zJ4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638312473266,"user_tz":-540,"elapsed":9562,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"0fc45c3c-0cb6-465e-d5e0-7386920d73b6"},"source":["!pip install transformers\n","!pip install sentencepiece==0.1.91"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 6.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 66.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 60.7 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 55.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n","Collecting sentencepiece==0.1.91\n","  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 6.5 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.91\n"]}]},{"cell_type":"code","metadata":{"id":"Rq5OaFeFbap_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638144128912,"user_tz":-540,"elapsed":699,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"fc3c10c3-143a-4a52-aad8-e3adac5935ff"},"source":["!git clone https://github.com/AIRC-KETI/ke-t5.git"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ke-t5'...\n","remote: Enumerating objects: 197, done.\u001b[K\n","remote: Counting objects: 100% (197/197), done.\u001b[K\n","remote: Compressing objects: 100% (172/172), done.\u001b[K\n","remote: Total 197 (delta 111), reused 85 (delta 13), pack-reused 0\u001b[K\n","Receiving objects: 100% (197/197), 783.74 KiB | 12.06 MiB/s, done.\n","Resolving deltas: 100% (111/111), done.\n"]}]},{"cell_type":"code","metadata":{"id":"qQirNfb4bcaq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638144128912,"user_tz":-540,"elapsed":5,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"481db7c3-fab6-4133-a744-156e3acc55db"},"source":["cd /content/ke-t5"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ke-t5\n"]}]},{"cell_type":"markdown","metadata":{"id":"CYBZdQIKQ4Vl"},"source":["transformers version = '4.12.5'"]},{"cell_type":"markdown","metadata":{"id":"lPfEMbfCEo5u"},"source":["런타임 다시 시작 눌러야할 수 있음  \n","만일 tokenizer Nonetype 에러시 런타임 다시 시작"]},{"cell_type":"code","metadata":{"id":"V43hOR_o8t8Y","colab":{"base_uri":"https://localhost:8080/","height":233,"referenced_widgets":["2513be19c6334d38bf82004a8568c27d","7b8275241ec8496e97ec0d73a406a727","8100d85f82224e7380a08b60c90095c7","41095125a446427b8150b4c62098c13e","88f6187f0e8646a68203a2044580ee64","cdf8dcde4ee34e559859143cc021ce89","fb833200f357407da6234e0b2b92959e","beb3290c8a684a95aa677960c18366e7","629b0081677142dab8edfc28d115c2f8","f188d277fc824b71830f7e223ad5d20e","5073655130b6460996fa1bc9cee52497","b9dc38df5eaa40a7b9d1426cb8d96d7a","1081bfafb3bf47b2bc65885bfb83b833","29066060e9b441a3ae5a3ed278a89faa","91c699821f3941c68267d355a9170d48","4728e767509945b7b15e9282012ebf1d","fa4d348928fd4667b01a18039b205c47","fe98a623dade43d0a68e8b94f7497614","b02996421b994c17ad530c0067e2cbd1","fd87c088d1a04a10b1354d6d9bd87270","b71e815122794f959d191c2f3263cc02","5d7430df58e441368d1d203d5493bb29","0b1c6eceb5374f228e4cc2e7d1c8ea3e","fad790e5add94d579391a0c7e9058ee1","306bcdd2d4164f668e34d5cab0aea56d","b66496c164af4e1ab076533353fb224c","3086fa9b64684cb4a6fe31537beedc79","23cf5db65cee4949ba3e0954c0978ffd","b7c5137eb2e7475ea5ae51869821a0ff","78c72d5e94354d22a901bbaa6699928d","5d09a0f07a7d415483fd7e8a2acb2e8b","340a8455dcdf455e9b94a392cad06f8c","341211f640664e55a119e75c6b105a34","5f864586d84d4373a5589e9a8312fd42","34928679beca4ac49823ba4404b3a60f","e17df36f30b04da9874a90478e4a0fec","2c0a2119043b45deb3f0beb2945388ce","ed2eebf3ed494f2ab4e73d79d1cf027b","edc19f0791944624aed879d7e146be78","7449ba4d0e3e449f968dcd159a508fce","d7e9b9b71114411c8ecc87bede7ac238","6d68d568c4c44de8accf8002782fabc1","622da2aae1c84f5fa53a9f9f7c41ef73","c77dc3ecb51d445b9efd7c3f3f6e8a6d","7ed37c8611364d35914b2e4061734ce4","7697bf98fbe04cef8ffe15b32a050810","8d01b27deb5d4168b9f2ec32828e98cf","7553afa8fc184b368a6565d09587f67e","b2a2e5253d3d42d08ab269fb49f3c61e","fba1c0a8509647fa8a7b48976bdf39d6","c401f7ee828e4dc399eae6d268875506","668d822c7e194fb68b8d6e74ee5086f1","f057f8be8a9b4df781845221a17691d6","ba43630d133f4b72bcf371bf7893f257","7388e556b6464ae6a396761f849f034f"]},"executionInfo":{"status":"ok","timestamp":1638232195343,"user_tz":-540,"elapsed":30506,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"ee4ff051-0ef0-4833-9ceb-25d286c829bf"},"source":["# model.generate(pieces)\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","from tqdm import tqdm\n","import torch\n","from torch.utils.data import DataLoader\n","\n","\n","model_folder = 'KETI-AIR/ke-t5-base'\n","\n","model = T5ForConditionalGeneration.from_pretrained(model_folder)\n","tokenizer = T5Tokenizer.from_pretrained(model_folder)"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2513be19c6334d38bf82004a8568c27d","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/599 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9dc38df5eaa40a7b9d1426cb8d96d7a","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/944M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b1c6eceb5374f228e4cc2e7d1c8ea3e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f864586d84d4373a5589e9a8312fd42","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ed37c8611364d35914b2e4061734ce4","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"e34lHWGtsSWd","executionInfo":{"status":"ok","timestamp":1638312491016,"user_tz":-540,"elapsed":912,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"LeNA2dpdtAVi","executionInfo":{"status":"ok","timestamp":1638312491017,"user_tz":-540,"elapsed":2,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["class CustomDataset:\n","\n","    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.source_len = source_len\n","        self.summ_len = summ_len\n","        self.text = self.data.text\n","        self.ctext = self.data.ctext\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        ctext = str(self.ctext[index])\n","        ctext = ' '.join(ctext.split())\n","\n","        text = str(self.text[index])\n","        text = ' '.join(text.split())\n","\n","        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n","        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n","\n","        source_ids = source['input_ids'].squeeze()\n","        source_mask = source['attention_mask'].squeeze()\n","        target_ids = target['input_ids'].squeeze()\n","        target_mask = target['attention_mask'].squeeze()\n","\n","        return {\n","            'source_ids': source_ids.to(dtype=torch.long), \n","            'source_mask': source_mask.to(dtype=torch.long), \n","            'target_ids': target_ids.to(dtype=torch.long),\n","            'target_ids_y': target_ids.to(dtype=torch.long)\n","        }"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcvmRVxasS_d","executionInfo":{"status":"ok","timestamp":1638312491017,"user_tz":-540,"elapsed":2,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["def train(epoch, tokenizer, model, device, loader, optimizer):\n","    model.train()\n","    for _,data in tqdm(enumerate(loader, 0)):\n","        y = data['target_ids'].to(device, dtype = torch.long)\n","        y_ids = y[:, :-1].contiguous()\n","        lm_labels = y[:, 1:].clone().detach()\n","        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n","        ids = data['source_ids'].to(device, dtype = torch.long)\n","        mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n","        loss = outputs[0]\n","        \n","        if _%10 == 0:\n","            pass\n","            \n","        if _%500==0:\n","            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # xm.optimizer_step(optimizer)\n","        # xm.mark_step()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ww9SpZIhsS8O","executionInfo":{"status":"ok","timestamp":1638312491017,"user_tz":-540,"elapsed":2,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["def validate(epoch, tokenizer, model, device, loader):\n","    model.eval()\n","    predictions = []\n","    actuals = []\n","    with torch.no_grad():\n","        for _, data in enumerate(loader, 0):\n","            y = data['target_ids'].to(device, dtype = torch.long)\n","            ids = data['source_ids'].to(device, dtype = torch.long)\n","            mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","            generated_ids = model.generate(\n","                input_ids = ids,\n","                attention_mask = mask, \n","                max_length=150, \n","                num_beams=2,\n","                repetition_penalty=2.5, \n","                length_penalty=1.0, \n","                early_stopping=True\n","                )\n","            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n","            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n","            if _%100==0:\n","                print(f'Completed {_}')\n","\n","            predictions.extend(preds)\n","            actuals.extend(target)\n","    return predictions, actuals"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Li1ZjzuosS5o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638232206747,"user_tz":-540,"elapsed":11413,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"41ecd89e-f65f-43ce-d451-2b4ddd3fe741"},"source":["model.to(device)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(64128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(64128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(64128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=64128, bias=False)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"HPz-4_59r3Jt"},"source":["hyper-parameters"]},{"cell_type":"code","metadata":{"id":"t4X-sowScRmo","executionInfo":{"status":"ok","timestamp":1638312500433,"user_tz":-540,"elapsed":358,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["from transformers import T5Config"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"UbU1ySuJsS36","executionInfo":{"status":"ok","timestamp":1638312501233,"user_tz":-540,"elapsed":413,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["config = T5Config()\n","config.MAX_LEN = 1024\n","config.SUMMARY_LEN = 150 \n","config.TRAIN_BATCH_SIZE = 2    # input batch size for training (default: 64)\n","config.VALID_BATCH_SIZE = 2    # input batch size for testing (default: 1000)\n","config.TRAIN_EPOCHS = 3        # number of epochs to train (default: 10)\n","config.VAL_EPOCHS = 1 \n","config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n","config.SEED = 42               # random seed (default: 42)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hLshDtNsS1R","executionInfo":{"status":"ok","timestamp":1638312503178,"user_tz":-540,"elapsed":1,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["train_params = {\n","        'batch_size': config.TRAIN_BATCH_SIZE,\n","        'shuffle': True,\n","        'num_workers': 0\n","        }\n","\n","val_params = {\n","        'batch_size': config.VALID_BATCH_SIZE,\n","        'shuffle': False,\n","        'num_workers': 0\n","        }\n","\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"xrru0dvtxaWA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638232206749,"user_tz":-540,"elapsed":22,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"cc4e34d6-b6db-4f76-fdaf-8a029e61706f"},"source":["!nvidia-smi"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Nov 30 00:30:05 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    35W / 250W |   2131MiB / 16280MiB |     13%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"1z5DClk92JFV","executionInfo":{"status":"ok","timestamp":1638232224454,"user_tz":-540,"elapsed":16843,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["import pandas as pd\n","train_dataset = pd.read_csv('/content/drive/MyDrive/3차 프로젝트/dataset/train.csv')[['document','label']]\n","validation_dataset = pd.read_csv('/content/drive/MyDrive/3차 프로젝트/dataset/valid.csv')[['document','label']]"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9tOihkaIsAAq"},"source":["partial dataset\n"]},{"cell_type":"code","metadata":{"id":"stFdG8LTrseJ","executionInfo":{"status":"ok","timestamp":1638074820316,"user_tz":-540,"elapsed":22,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["import numpy as np\n","\n","train_dataset = train_dataset[55000:135000]\n","validation_dataset = validation_dataset[:1000]"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I4JFTHoisIGQ"},"source":["##train"]},{"cell_type":"code","metadata":{"id":"U7e4LNJssSzF","colab":{"base_uri":"https://localhost:8080/","height":494},"executionInfo":{"status":"error","timestamp":1637820973853,"user_tz":-540,"elapsed":15369,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"a5eb8004-33ac-4dcb-98ba-a99b69667eb4"},"source":["train_dataset.columns = ['ctext','text']\n","train_dataset.ctext = 'summarize: ' + train_dataset.ctext\n","\n","training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","\n","training_loader = DataLoader(training_set, **train_params)\n","\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n","for epoch in range(config.TRAIN_EPOCHS):\n","    print (1)\n","    train(epoch, tokenizer, model, device, training_loader, optimizer)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.2922163009643555\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","32it [00:14,  2.16it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-2ec1310825e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-120e3ec83780>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, tokenizer, model, device, loader, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         )\n\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_seq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mencoder_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"lgE-LRHAzhOR"},"source":["tokenizer.save_pretrained('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU2')\n","model.save_pretrained('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU2')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G2OKiEwzsKTs"},"source":["## valid(test)"]},{"cell_type":"code","metadata":{"id":"h0ly0z2xsSwq"},"source":["validation_dataset.columns = ['ctext','text']\n","validation_dataset.ctext = 'summarize: ' + validation_dataset.ctext\n","\n","val_set = CustomDataset(validation_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","\n","val_loader = DataLoader(val_set, **val_params)\n","\n","for epoch in range(config.VAL_EPOCHS):\n","    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n","    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n","\n","final_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9wRh7tMjyRVx"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"50o3KCF1vY01"},"source":["## 반복"]},{"cell_type":"code","metadata":{"id":"w7TSYl1QjDR0","executionInfo":{"status":"ok","timestamp":1638144187744,"user_tz":-540,"elapsed":14510,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["from transformers import T5Tokenizer, T5ForConditionalGeneration\n","from tqdm import tqdm\n","import torch\n","from torch.utils.data import DataLoader\n","\n","\n","model_folder = '/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU'\n","\n","model = T5ForConditionalGeneration.from_pretrained(model_folder)\n","tokenizer = T5Tokenizer.from_pretrained(model_folder)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uE6pbGgmwQK0","executionInfo":{"status":"ok","timestamp":1638144188141,"user_tz":-540,"elapsed":398,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"8449a104-2e84-46ed-eb38-0a7bb730448f"},"source":["model.to(device)"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(64128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(64128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(64128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=64128, bias=False)\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"3nCHuunlwZEP","executionInfo":{"status":"ok","timestamp":1638144188142,"user_tz":-540,"elapsed":3,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["train_params = {\n","        'batch_size': config.TRAIN_BATCH_SIZE,\n","        'shuffle': True,\n","        'num_workers': 0\n","        }\n","\n","val_params = {\n","        'batch_size': config.VALID_BATCH_SIZE,\n","        'shuffle': False,\n","        'num_workers': 0\n","        }\n","\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"KIFLx4BCyhx0","executionInfo":{"status":"ok","timestamp":1638144195546,"user_tz":-540,"elapsed":7407,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["import pandas as pd\n","train_dataset = pd.read_csv('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/dataset for test/first.csv')[['document','label']]\n","validation_dataset = pd.read_csv('/content/drive/MyDrive/3차 프로젝트/dataset/valid.csv')[['document','label']]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"kLJMrg8mt-OM","executionInfo":{"status":"ok","timestamp":1638144195547,"user_tz":-540,"elapsed":28,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["import numpy as np\n","\n","train_dataset = train_dataset\n","validation_dataset = validation_dataset[:1000]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vrxTJJrbuB6n","executionInfo":{"status":"ok","timestamp":1638198795987,"user_tz":-540,"elapsed":54600466,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"a1d04704-9f6c-4d3a-b760-69ce394d8f88"},"source":["train_dataset.columns = ['ctext','text']\n","train_dataset.ctext = 'summarize: ' + train_dataset.ctext\n","\n","training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","\n","training_loader = DataLoader(training_set, **train_params)\n","\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n","for epoch in range(config.TRAIN_EPOCHS):\n","    print (1)\n","    train(epoch, tokenizer, model, device, training_loader, optimizer)"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.512315511703491\n"]},{"output_type":"stream","name":"stderr","text":["500it [03:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.6025278568267822\n"]},{"output_type":"stream","name":"stderr","text":["1000it [07:35,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.061852216720581\n"]},{"output_type":"stream","name":"stderr","text":["1500it [11:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.2685494422912598\n"]},{"output_type":"stream","name":"stderr","text":["2000it [15:10,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.8727003335952759\n"]},{"output_type":"stream","name":"stderr","text":["2500it [18:57,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.9439266920089722\n"]},{"output_type":"stream","name":"stderr","text":["3000it [22:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.6072962284088135\n"]},{"output_type":"stream","name":"stderr","text":["3500it [26:32,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  0.9631649851799011\n"]},{"output_type":"stream","name":"stderr","text":["4000it [30:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.8391841650009155\n"]},{"output_type":"stream","name":"stderr","text":["4500it [34:07,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.4884017705917358\n"]},{"output_type":"stream","name":"stderr","text":["5000it [37:54,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.394180178642273\n"]},{"output_type":"stream","name":"stderr","text":["5500it [41:42,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7923698425292969\n"]},{"output_type":"stream","name":"stderr","text":["6000it [45:29,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.354445457458496\n"]},{"output_type":"stream","name":"stderr","text":["6500it [49:17,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.8664402961730957\n"]},{"output_type":"stream","name":"stderr","text":["7000it [53:04,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.0731570720672607\n"]},{"output_type":"stream","name":"stderr","text":["7500it [56:52,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.002098560333252\n"]},{"output_type":"stream","name":"stderr","text":["8000it [1:00:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.2881131172180176\n"]},{"output_type":"stream","name":"stderr","text":["8500it [1:04:27,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.0426963567733765\n"]},{"output_type":"stream","name":"stderr","text":["9000it [1:08:14,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.2321395874023438\n"]},{"output_type":"stream","name":"stderr","text":["9500it [1:12:02,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.4372663497924805\n"]},{"output_type":"stream","name":"stderr","text":["10000it [1:15:49,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.2617552280426025\n"]},{"output_type":"stream","name":"stderr","text":["10500it [1:19:36,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.319392204284668\n"]},{"output_type":"stream","name":"stderr","text":["11000it [1:23:24,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.6803747415542603\n"]},{"output_type":"stream","name":"stderr","text":["11500it [1:27:12,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.3422963619232178\n"]},{"output_type":"stream","name":"stderr","text":["12000it [1:30:59,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.654374361038208\n"]},{"output_type":"stream","name":"stderr","text":["12500it [1:34:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.1335813999176025\n"]},{"output_type":"stream","name":"stderr","text":["13000it [1:38:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.869309902191162\n"]},{"output_type":"stream","name":"stderr","text":["13500it [1:42:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7821569442749023\n"]},{"output_type":"stream","name":"stderr","text":["14000it [1:46:09,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5243995189666748\n"]},{"output_type":"stream","name":"stderr","text":["14500it [1:49:57,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5289119482040405\n"]},{"output_type":"stream","name":"stderr","text":["15000it [1:53:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.651459217071533\n"]},{"output_type":"stream","name":"stderr","text":["15500it [1:57:32,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  3.050774097442627\n"]},{"output_type":"stream","name":"stderr","text":["16000it [2:01:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.1804943084716797\n"]},{"output_type":"stream","name":"stderr","text":["16500it [2:05:07,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.8513084650039673\n"]},{"output_type":"stream","name":"stderr","text":["17000it [2:08:54,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5157781839370728\n"]},{"output_type":"stream","name":"stderr","text":["17500it [2:12:42,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.6810266971588135\n"]},{"output_type":"stream","name":"stderr","text":["18000it [2:16:29,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.775113821029663\n"]},{"output_type":"stream","name":"stderr","text":["18500it [2:20:16,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  3.446455478668213\n"]},{"output_type":"stream","name":"stderr","text":["19000it [2:24:04,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.079845666885376\n"]},{"output_type":"stream","name":"stderr","text":["19500it [2:27:51,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.035710573196411\n"]},{"output_type":"stream","name":"stderr","text":["20000it [2:31:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.4873225688934326\n"]},{"output_type":"stream","name":"stderr","text":["20500it [2:35:26,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.9470523595809937\n"]},{"output_type":"stream","name":"stderr","text":["21000it [2:39:14,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.115370035171509\n"]},{"output_type":"stream","name":"stderr","text":["21500it [2:43:01,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.3418396711349487\n"]},{"output_type":"stream","name":"stderr","text":["22000it [2:46:49,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.9731104373931885\n"]},{"output_type":"stream","name":"stderr","text":["22500it [2:50:36,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7444056272506714\n"]},{"output_type":"stream","name":"stderr","text":["23000it [2:54:23,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.197599172592163\n"]},{"output_type":"stream","name":"stderr","text":["23500it [2:58:11,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.236307978630066\n"]},{"output_type":"stream","name":"stderr","text":["24000it [3:01:58,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  3.0047717094421387\n"]},{"output_type":"stream","name":"stderr","text":["24500it [3:05:46,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  3.30222487449646\n"]},{"output_type":"stream","name":"stderr","text":["25000it [3:09:33,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.240471839904785\n"]},{"output_type":"stream","name":"stderr","text":["25500it [3:13:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.2750300168991089\n"]},{"output_type":"stream","name":"stderr","text":["26000it [3:17:08,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.8176701068878174\n"]},{"output_type":"stream","name":"stderr","text":["26500it [3:20:56,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.659609079360962\n"]},{"output_type":"stream","name":"stderr","text":["27000it [3:24:43,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5329830646514893\n"]},{"output_type":"stream","name":"stderr","text":["27500it [3:28:31,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7527570724487305\n"]},{"output_type":"stream","name":"stderr","text":["28000it [3:32:18,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.1592390537261963\n"]},{"output_type":"stream","name":"stderr","text":["28500it [3:36:06,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5703272819519043\n"]},{"output_type":"stream","name":"stderr","text":["29000it [3:39:53,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.0381662845611572\n"]},{"output_type":"stream","name":"stderr","text":["29500it [3:43:40,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7734498977661133\n"]},{"output_type":"stream","name":"stderr","text":["30000it [3:47:28,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.3416779041290283\n"]},{"output_type":"stream","name":"stderr","text":["30500it [3:51:15,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.857344150543213\n"]},{"output_type":"stream","name":"stderr","text":["31000it [3:55:03,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.2545151710510254\n"]},{"output_type":"stream","name":"stderr","text":["31500it [3:58:50,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.106520891189575\n"]},{"output_type":"stream","name":"stderr","text":["32000it [4:02:38,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.517754077911377\n"]},{"output_type":"stream","name":"stderr","text":["32500it [4:06:25,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.2632851600646973\n"]},{"output_type":"stream","name":"stderr","text":["33000it [4:10:13,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5170130729675293\n"]},{"output_type":"stream","name":"stderr","text":["33500it [4:14:00,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.2282555103302002\n"]},{"output_type":"stream","name":"stderr","text":["34000it [4:17:48,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.6286029815673828\n"]},{"output_type":"stream","name":"stderr","text":["34500it [4:21:35,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  3.0573971271514893\n"]},{"output_type":"stream","name":"stderr","text":["35000it [4:25:23,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.3768343925476074\n"]},{"output_type":"stream","name":"stderr","text":["35500it [4:29:10,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.9141334295272827\n"]},{"output_type":"stream","name":"stderr","text":["36000it [4:32:58,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.1287646293640137\n"]},{"output_type":"stream","name":"stderr","text":["36500it [4:36:45,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.7674827575683594\n"]},{"output_type":"stream","name":"stderr","text":["37000it [4:40:32,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  0.9638612270355225\n"]},{"output_type":"stream","name":"stderr","text":["37500it [4:44:20,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  3.0629115104675293\n"]},{"output_type":"stream","name":"stderr","text":["38000it [4:48:07,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  0.7618783712387085\n"]},{"output_type":"stream","name":"stderr","text":["38500it [4:51:55,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.382964849472046\n"]},{"output_type":"stream","name":"stderr","text":["39000it [4:55:42,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.931876540184021\n"]},{"output_type":"stream","name":"stderr","text":["39500it [4:59:30,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7248554229736328\n"]},{"output_type":"stream","name":"stderr","text":["40000it [5:03:17,  2.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.10587477684021\n"]},{"output_type":"stream","name":"stderr","text":["500it [03:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.5981151461601257\n"]},{"output_type":"stream","name":"stderr","text":["1000it [07:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.3261661529541016\n"]},{"output_type":"stream","name":"stderr","text":["1500it [11:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3784915208816528\n"]},{"output_type":"stream","name":"stderr","text":["2000it [15:09,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.8335902690887451\n"]},{"output_type":"stream","name":"stderr","text":["2500it [18:57,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.7503880262374878\n"]},{"output_type":"stream","name":"stderr","text":["3000it [22:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2374190092086792\n"]},{"output_type":"stream","name":"stderr","text":["3500it [26:31,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.6756998300552368\n"]},{"output_type":"stream","name":"stderr","text":["4000it [30:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.3450570106506348\n"]},{"output_type":"stream","name":"stderr","text":["4500it [34:06,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.8451608419418335\n"]},{"output_type":"stream","name":"stderr","text":["5000it [37:54,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4564688205718994\n"]},{"output_type":"stream","name":"stderr","text":["5500it [41:41,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.6489245891571045\n"]},{"output_type":"stream","name":"stderr","text":["6000it [45:29,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.7541720867156982\n"]},{"output_type":"stream","name":"stderr","text":["6500it [49:16,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.0211892127990723\n"]},{"output_type":"stream","name":"stderr","text":["7000it [53:04,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.980611801147461\n"]},{"output_type":"stream","name":"stderr","text":["7500it [56:51,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.5406033992767334\n"]},{"output_type":"stream","name":"stderr","text":["8000it [1:00:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2418076992034912\n"]},{"output_type":"stream","name":"stderr","text":["8500it [1:04:26,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.5299924612045288\n"]},{"output_type":"stream","name":"stderr","text":["9000it [1:08:14,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3162810802459717\n"]},{"output_type":"stream","name":"stderr","text":["9500it [1:12:01,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.537420392036438\n"]},{"output_type":"stream","name":"stderr","text":["10000it [1:15:48,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.6231179237365723\n"]},{"output_type":"stream","name":"stderr","text":["10500it [1:19:36,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.8879266977310181\n"]},{"output_type":"stream","name":"stderr","text":["11000it [1:23:23,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.0878276824951172\n"]},{"output_type":"stream","name":"stderr","text":["11500it [1:27:11,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.439541816711426\n"]},{"output_type":"stream","name":"stderr","text":["12000it [1:30:58,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.261079788208008\n"]},{"output_type":"stream","name":"stderr","text":["12500it [1:34:46,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.9100489616394043\n"]},{"output_type":"stream","name":"stderr","text":["13000it [1:38:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1445364952087402\n"]},{"output_type":"stream","name":"stderr","text":["13500it [1:42:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.9314743280410767\n"]},{"output_type":"stream","name":"stderr","text":["14000it [1:46:08,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.6614582538604736\n"]},{"output_type":"stream","name":"stderr","text":["14500it [1:49:56,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.7388836145401\n"]},{"output_type":"stream","name":"stderr","text":["15000it [1:53:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  3.1214215755462646\n"]},{"output_type":"stream","name":"stderr","text":["15500it [1:57:31,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  3.1032705307006836\n"]},{"output_type":"stream","name":"stderr","text":["16000it [2:01:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.8049170970916748\n"]},{"output_type":"stream","name":"stderr","text":["16500it [2:05:06,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.428607702255249\n"]},{"output_type":"stream","name":"stderr","text":["17000it [2:08:54,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.253787636756897\n"]},{"output_type":"stream","name":"stderr","text":["17500it [2:12:41,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.5344732999801636\n"]},{"output_type":"stream","name":"stderr","text":["18000it [2:16:29,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1093608140945435\n"]},{"output_type":"stream","name":"stderr","text":["18500it [2:20:16,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2628775835037231\n"]},{"output_type":"stream","name":"stderr","text":["19000it [2:24:04,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4337430000305176\n"]},{"output_type":"stream","name":"stderr","text":["19500it [2:27:51,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.2890822887420654\n"]},{"output_type":"stream","name":"stderr","text":["20000it [2:31:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.9438365697860718\n"]},{"output_type":"stream","name":"stderr","text":["20500it [2:35:26,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.8282040357589722\n"]},{"output_type":"stream","name":"stderr","text":["21000it [2:39:14,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.2027575969696045\n"]},{"output_type":"stream","name":"stderr","text":["21500it [2:43:01,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.5453060865402222\n"]},{"output_type":"stream","name":"stderr","text":["22000it [2:46:49,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.9266541004180908\n"]},{"output_type":"stream","name":"stderr","text":["22500it [2:50:37,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.2001349925994873\n"]},{"output_type":"stream","name":"stderr","text":["23000it [2:54:24,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1075003147125244\n"]},{"output_type":"stream","name":"stderr","text":["23500it [2:58:12,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.502370834350586\n"]},{"output_type":"stream","name":"stderr","text":["24000it [3:01:59,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4921209812164307\n"]},{"output_type":"stream","name":"stderr","text":["24500it [3:05:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.082033634185791\n"]},{"output_type":"stream","name":"stderr","text":["25000it [3:09:35,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.5280345678329468\n"]},{"output_type":"stream","name":"stderr","text":["25500it [3:13:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.055514097213745\n"]},{"output_type":"stream","name":"stderr","text":["26000it [3:17:10,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.3920915126800537\n"]},{"output_type":"stream","name":"stderr","text":["26500it [3:20:57,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.6455132365226746\n"]},{"output_type":"stream","name":"stderr","text":["27000it [3:24:45,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4380720853805542\n"]},{"output_type":"stream","name":"stderr","text":["27500it [3:28:32,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.0939953327178955\n"]},{"output_type":"stream","name":"stderr","text":["28000it [3:32:20,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4033108949661255\n"]},{"output_type":"stream","name":"stderr","text":["28500it [3:36:07,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.2034928798675537\n"]},{"output_type":"stream","name":"stderr","text":["29000it [3:39:54,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.4624903202056885\n"]},{"output_type":"stream","name":"stderr","text":["29500it [3:43:42,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  3.4767327308654785\n"]},{"output_type":"stream","name":"stderr","text":["30000it [3:47:29,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3050713539123535\n"]},{"output_type":"stream","name":"stderr","text":["30500it [3:51:17,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.419926643371582\n"]},{"output_type":"stream","name":"stderr","text":["31000it [3:55:04,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1556813716888428\n"]},{"output_type":"stream","name":"stderr","text":["31500it [3:58:52,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.7392830848693848\n"]},{"output_type":"stream","name":"stderr","text":["32000it [4:02:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4446312189102173\n"]},{"output_type":"stream","name":"stderr","text":["32500it [4:06:27,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.294278621673584\n"]},{"output_type":"stream","name":"stderr","text":["33000it [4:10:14,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4556444883346558\n"]},{"output_type":"stream","name":"stderr","text":["33500it [4:14:02,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.9457204937934875\n"]},{"output_type":"stream","name":"stderr","text":["34000it [4:17:49,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.0665446519851685\n"]},{"output_type":"stream","name":"stderr","text":["34500it [4:21:37,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.9930992126464844\n"]},{"output_type":"stream","name":"stderr","text":["35000it [4:25:24,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.5735676288604736\n"]},{"output_type":"stream","name":"stderr","text":["35500it [4:29:12,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.8791748881340027\n"]},{"output_type":"stream","name":"stderr","text":["36000it [4:32:59,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.1768388748168945\n"]},{"output_type":"stream","name":"stderr","text":["36500it [4:36:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2398930788040161\n"]},{"output_type":"stream","name":"stderr","text":["37000it [4:40:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.1326472759246826\n"]},{"output_type":"stream","name":"stderr","text":["37500it [4:44:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3547927141189575\n"]},{"output_type":"stream","name":"stderr","text":["38000it [4:48:09,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1940933465957642\n"]},{"output_type":"stream","name":"stderr","text":["38500it [4:51:57,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.7167837619781494\n"]},{"output_type":"stream","name":"stderr","text":["39000it [4:55:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2887736558914185\n"]},{"output_type":"stream","name":"stderr","text":["39500it [4:59:32,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.4397237300872803\n"]},{"output_type":"stream","name":"stderr","text":["40000it [5:03:19,  2.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.9297451972961426\n"]},{"output_type":"stream","name":"stderr","text":["500it [03:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0860446691513062\n"]},{"output_type":"stream","name":"stderr","text":["1000it [07:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.69062340259552\n"]},{"output_type":"stream","name":"stderr","text":["1500it [11:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.349968671798706\n"]},{"output_type":"stream","name":"stderr","text":["2000it [15:09,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.3401763439178467\n"]},{"output_type":"stream","name":"stderr","text":["2500it [18:57,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.7675668001174927\n"]},{"output_type":"stream","name":"stderr","text":["3000it [22:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.259945273399353\n"]},{"output_type":"stream","name":"stderr","text":["3500it [26:32,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.315049648284912\n"]},{"output_type":"stream","name":"stderr","text":["4000it [30:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.7282338738441467\n"]},{"output_type":"stream","name":"stderr","text":["4500it [34:07,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0127907991409302\n"]},{"output_type":"stream","name":"stderr","text":["5000it [37:54,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.003900408744812\n"]},{"output_type":"stream","name":"stderr","text":["5500it [41:42,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.7831438779830933\n"]},{"output_type":"stream","name":"stderr","text":["6000it [45:29,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.12801194190979\n"]},{"output_type":"stream","name":"stderr","text":["6500it [49:17,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.2416412830352783\n"]},{"output_type":"stream","name":"stderr","text":["7000it [53:04,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.1286543607711792\n"]},{"output_type":"stream","name":"stderr","text":["7500it [56:52,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.631448745727539\n"]},{"output_type":"stream","name":"stderr","text":["8000it [1:00:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.3223907947540283\n"]},{"output_type":"stream","name":"stderr","text":["8500it [1:04:26,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0497115850448608\n"]},{"output_type":"stream","name":"stderr","text":["9000it [1:08:14,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.3877713680267334\n"]},{"output_type":"stream","name":"stderr","text":["9500it [1:12:01,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.671104371547699\n"]},{"output_type":"stream","name":"stderr","text":["10000it [1:15:49,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.448794364929199\n"]},{"output_type":"stream","name":"stderr","text":["10500it [1:19:36,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.8499467372894287\n"]},{"output_type":"stream","name":"stderr","text":["11000it [1:23:24,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.6142396926879883\n"]},{"output_type":"stream","name":"stderr","text":["11500it [1:27:11,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.3108545541763306\n"]},{"output_type":"stream","name":"stderr","text":["12000it [1:30:59,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0339292287826538\n"]},{"output_type":"stream","name":"stderr","text":["12500it [1:34:46,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.039149284362793\n"]},{"output_type":"stream","name":"stderr","text":["13000it [1:38:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4254363775253296\n"]},{"output_type":"stream","name":"stderr","text":["13500it [1:42:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.3313463926315308\n"]},{"output_type":"stream","name":"stderr","text":["14000it [1:46:09,  2.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.682548761367798\n"]},{"output_type":"stream","name":"stderr","text":["14500it [1:49:56,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0030351877212524\n"]},{"output_type":"stream","name":"stderr","text":["15000it [1:53:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.7954899072647095\n"]},{"output_type":"stream","name":"stderr","text":["15500it [1:57:31,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.5175765752792358\n"]},{"output_type":"stream","name":"stderr","text":["16000it [2:01:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.213235378265381\n"]},{"output_type":"stream","name":"stderr","text":["16500it [2:05:06,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.18278431892395\n"]},{"output_type":"stream","name":"stderr","text":["17000it [2:08:54,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.2238997220993042\n"]},{"output_type":"stream","name":"stderr","text":["17500it [2:12:41,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.8417646884918213\n"]},{"output_type":"stream","name":"stderr","text":["18000it [2:16:29,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.5268588066101074\n"]},{"output_type":"stream","name":"stderr","text":["18500it [2:20:16,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.5944868326187134\n"]},{"output_type":"stream","name":"stderr","text":["19000it [2:24:04,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.050262928009033\n"]},{"output_type":"stream","name":"stderr","text":["19500it [2:27:51,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.9970555305480957\n"]},{"output_type":"stream","name":"stderr","text":["20000it [2:31:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.6434072256088257\n"]},{"output_type":"stream","name":"stderr","text":["20500it [2:35:26,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.6659226417541504\n"]},{"output_type":"stream","name":"stderr","text":["21000it [2:39:14,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.0593066215515137\n"]},{"output_type":"stream","name":"stderr","text":["21500it [2:43:01,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.4122982025146484\n"]},{"output_type":"stream","name":"stderr","text":["22000it [2:46:49,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.9669264554977417\n"]},{"output_type":"stream","name":"stderr","text":["22500it [2:50:36,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.4754140377044678\n"]},{"output_type":"stream","name":"stderr","text":["23000it [2:54:24,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0217680931091309\n"]},{"output_type":"stream","name":"stderr","text":["23500it [2:58:11,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0101803541183472\n"]},{"output_type":"stream","name":"stderr","text":["24000it [3:01:59,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.158698558807373\n"]},{"output_type":"stream","name":"stderr","text":["24500it [3:05:46,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.328264594078064\n"]},{"output_type":"stream","name":"stderr","text":["25000it [3:09:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.3719302415847778\n"]},{"output_type":"stream","name":"stderr","text":["25500it [3:13:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.2693381309509277\n"]},{"output_type":"stream","name":"stderr","text":["26000it [3:17:09,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.620805501937866\n"]},{"output_type":"stream","name":"stderr","text":["26500it [3:20:56,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.007912278175354\n"]},{"output_type":"stream","name":"stderr","text":["27000it [3:24:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.6612989902496338\n"]},{"output_type":"stream","name":"stderr","text":["27500it [3:28:32,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.8490315675735474\n"]},{"output_type":"stream","name":"stderr","text":["28000it [3:32:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.3766971826553345\n"]},{"output_type":"stream","name":"stderr","text":["28500it [3:36:07,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.395874500274658\n"]},{"output_type":"stream","name":"stderr","text":["29000it [3:39:55,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.3723669052124023\n"]},{"output_type":"stream","name":"stderr","text":["29500it [3:43:42,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.4612133502960205\n"]},{"output_type":"stream","name":"stderr","text":["30000it [3:47:30,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.6568485498428345\n"]},{"output_type":"stream","name":"stderr","text":["30500it [3:51:18,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.468092679977417\n"]},{"output_type":"stream","name":"stderr","text":["31000it [3:55:05,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4013140201568604\n"]},{"output_type":"stream","name":"stderr","text":["31500it [3:58:53,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.329370141029358\n"]},{"output_type":"stream","name":"stderr","text":["32000it [4:02:40,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.314570665359497\n"]},{"output_type":"stream","name":"stderr","text":["32500it [4:06:28,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.2432548999786377\n"]},{"output_type":"stream","name":"stderr","text":["33000it [4:10:16,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.8284116983413696\n"]},{"output_type":"stream","name":"stderr","text":["33500it [4:14:03,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.2964297533035278\n"]},{"output_type":"stream","name":"stderr","text":["34000it [4:17:51,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.5935643911361694\n"]},{"output_type":"stream","name":"stderr","text":["34500it [4:21:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.7330296039581299\n"]},{"output_type":"stream","name":"stderr","text":["35000it [4:25:26,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4392732381820679\n"]},{"output_type":"stream","name":"stderr","text":["35500it [4:29:14,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4799000024795532\n"]},{"output_type":"stream","name":"stderr","text":["36000it [4:33:02,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0129345655441284\n"]},{"output_type":"stream","name":"stderr","text":["36500it [4:36:49,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.8013862371444702\n"]},{"output_type":"stream","name":"stderr","text":["37000it [4:40:37,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.8549104332923889\n"]},{"output_type":"stream","name":"stderr","text":["37500it [4:44:25,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.19125497341156\n"]},{"output_type":"stream","name":"stderr","text":["38000it [4:48:12,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.994820237159729\n"]},{"output_type":"stream","name":"stderr","text":["38500it [4:52:00,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.9261751174926758\n"]},{"output_type":"stream","name":"stderr","text":["39000it [4:55:48,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4158421754837036\n"]},{"output_type":"stream","name":"stderr","text":["39500it [4:59:35,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.3885198831558228\n"]},{"output_type":"stream","name":"stderr","text":["40000it [5:03:23,  2.20it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"cJZmpjI3uEKH","executionInfo":{"status":"ok","timestamp":1638198812631,"user_tz":-540,"elapsed":16654,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["tokenizer.save_pretrained('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/1차')\n","model.save_pretrained('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/1차')"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":781},"id":"M74Kck4Qy3Mk","executionInfo":{"status":"ok","timestamp":1638199381714,"user_tz":-540,"elapsed":569098,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"e9cc4ffd-bfa7-4941-fda2-0fbc9b318e4f"},"source":["validation_dataset.columns = ['ctext','text']\n","validation_dataset.ctext = 'summarize: ' + validation_dataset.ctext\n","\n","val_set = CustomDataset(validation_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","\n","val_loader = DataLoader(val_set, **val_params)\n","\n","for epoch in range(config.VAL_EPOCHS):\n","    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n","    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n","\n","final_df"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Completed 0\n","Completed 100\n","Completed 200\n","Completed 300\n","Completed 400\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Generated Text</th>\n","      <th>Actual Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>큐브를 통해 악플러에 대한 고소장을 제출하며 강경대응을 예고했으며, 당사는 지난 8...</td>\n","      <td>가수 강다니엘이 모욕죄 혐의로 악플러에 대한 고소장을 서울강남경찰서에 제출하며 합의...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>큐브에서 의장·부의장 및 상임위원장 선거를 실시한 가운데, 안산시의회가 지역 청소년...</td>\n","      <td>안산시의회는 지난 7월 22일과 29일에 청소년의회 제1·2차 본회의를 열어 실제 ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>큐브 위반 혐의로 일본인 A(37)씨를 기소 의견으로 검찰에 송치됐다.</td>\n","      <td>2019 광주세계수영선수권대회에서 18일 일본인A씨가 12명의 여자선수들의 신체 일...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>큐브, 에디슨파크 등 다양한 공간활용으로 주거 생활제일건설은 익산시 선화로53길 8...</td>\n","      <td>제일건설은 실수요자들에게 선호도 높은 전용 면적과 효율적인 공간 활용을 강점으로 1...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>큐브종목 +14.87%, 한라IMS종목 +3.15%, 케이에스피종목+0.91% 순이다.</td>\n","      <td>월요일 11시 00분 현재 조선업종 내 상승종목 등락률 1위를 차지한 에이치엘비종목...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>큐브가 1차 강사채용 공고를 마감하고, 대학들은 '고등교육법 개정안'에 따라 1년의...</td>\n","      <td>오는 1일부터 '강사법' 시행을 앞둔 가운데 대학들은 고등교육법 개정안에 따른 1년...</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>큐브에서 참전유공자 배우자에게 월 9만원(만 65세 이상)부터 15만원(만 80세 ...</td>\n","      <td>제주특별자치도 보훈청은 지난 12일 이러한 내용을 담은 제주도 참전유공자 지원 조례...</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>큐브와 탕정.인주.선장 일반사업단지등 290만m2의 규모의 산업단지 10곳을 조성하...</td>\n","      <td>오세현 아산시장은 아산의 모든 역량과 기회를 지역경제 활성화에 집중하겠다며 지역경제...</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>큐브 여성아동범죄조사부(강수산나 부장검사)는 출생 신고를 하지 않은 아이를 방치해 ...</td>\n","      <td>서울남부지검 여성아동범죄조사부는 2010년 10월에 낳은 여자 아이에게 예방접종을 ...</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>큐브 정국 이후 지속돼온 냉전 대립구도가 더욱 고착될 수 있다는 우려도 적지 않아 ...</td>\n","      <td>문재인 대통령은 29일 청와대에서 주재한 을지태극 국무회의 모두발언에서 한국당 강효...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                        Generated Text                                        Actual Text\n","0    큐브를 통해 악플러에 대한 고소장을 제출하며 강경대응을 예고했으며, 당사는 지난 8...  가수 강다니엘이 모욕죄 혐의로 악플러에 대한 고소장을 서울강남경찰서에 제출하며 합의...\n","1    큐브에서 의장·부의장 및 상임위원장 선거를 실시한 가운데, 안산시의회가 지역 청소년...  안산시의회는 지난 7월 22일과 29일에 청소년의회 제1·2차 본회의를 열어 실제 ...\n","2              큐브 위반 혐의로 일본인 A(37)씨를 기소 의견으로 검찰에 송치됐다.  2019 광주세계수영선수권대회에서 18일 일본인A씨가 12명의 여자선수들의 신체 일...\n","3    큐브, 에디슨파크 등 다양한 공간활용으로 주거 생활제일건설은 익산시 선화로53길 8...  제일건설은 실수요자들에게 선호도 높은 전용 면적과 효율적인 공간 활용을 강점으로 1...\n","4     큐브종목 +14.87%, 한라IMS종목 +3.15%, 케이에스피종목+0.91% 순이다.  월요일 11시 00분 현재 조선업종 내 상승종목 등락률 1위를 차지한 에이치엘비종목...\n","..                                                 ...                                                ...\n","995  큐브가 1차 강사채용 공고를 마감하고, 대학들은 '고등교육법 개정안'에 따라 1년의...  오는 1일부터 '강사법' 시행을 앞둔 가운데 대학들은 고등교육법 개정안에 따른 1년...\n","996  큐브에서 참전유공자 배우자에게 월 9만원(만 65세 이상)부터 15만원(만 80세 ...  제주특별자치도 보훈청은 지난 12일 이러한 내용을 담은 제주도 참전유공자 지원 조례...\n","997  큐브와 탕정.인주.선장 일반사업단지등 290만m2의 규모의 산업단지 10곳을 조성하...  오세현 아산시장은 아산의 모든 역량과 기회를 지역경제 활성화에 집중하겠다며 지역경제...\n","998  큐브 여성아동범죄조사부(강수산나 부장검사)는 출생 신고를 하지 않은 아이를 방치해 ...  서울남부지검 여성아동범죄조사부는 2010년 10월에 낳은 여자 아이에게 예방접종을 ...\n","999  큐브 정국 이후 지속돼온 냉전 대립구도가 더욱 고착될 수 있다는 우려도 적지 않아 ...  문재인 대통령은 29일 청와대에서 주재한 을지태극 국무회의 모두발언에서 한국당 강효...\n","\n","[1000 rows x 2 columns]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"VjVxnRuwy7Dn","executionInfo":{"status":"ok","timestamp":1638199381714,"user_tz":-540,"elapsed":6,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["final_df.to_csv('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/ke-t5_ver1.csv')"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"8u-t5ZfAudsk","executionInfo":{"status":"ok","timestamp":1638232237525,"user_tz":-540,"elapsed":12075,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["from transformers import T5Tokenizer, T5ForConditionalGeneration\n","from tqdm import tqdm\n","import torch\n","from torch.utils.data import DataLoader\n","\n","\n","model_folder = '/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/1차'\n","\n","model = T5ForConditionalGeneration.from_pretrained(model_folder)\n","tokenizer = T5Tokenizer.from_pretrained(model_folder)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vc0cfW1qwk6u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638232237916,"user_tz":-540,"elapsed":401,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"d23d3c27-d59e-4f05-bda5-2ffd02155750"},"source":["model.to(device)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(64128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(64128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(64128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=64128, bias=False)\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"nUc6FghvwnQp","executionInfo":{"status":"ok","timestamp":1638232237918,"user_tz":-540,"elapsed":6,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["train_params = {\n","        'batch_size': config.TRAIN_BATCH_SIZE,\n","        'shuffle': True,\n","        'num_workers': 0\n","        }\n","\n","val_params = {\n","        'batch_size': config.VALID_BATCH_SIZE,\n","        'shuffle': False,\n","        'num_workers': 0\n","        }\n","\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"bTcDu_xBzJRh","executionInfo":{"status":"ok","timestamp":1638232243346,"user_tz":-540,"elapsed":5110,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["import pandas as pd\n","train_dataset = pd.read_csv('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/dataset for test/second.csv')[['document','label']]\n","validation_dataset = pd.read_csv('/content/drive/MyDrive/3차 프로젝트/dataset/valid.csv')[['document','label']]"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"-DgT6wx3uMnH","executionInfo":{"status":"ok","timestamp":1638232243346,"user_tz":-540,"elapsed":27,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["import numpy as np\n","\n","train_dataset = train_dataset\n","validation_dataset = validation_dataset[1000:2000]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"054b0-2iuP3M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638286793041,"user_tz":-540,"elapsed":54549720,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"d46ea78f-03e1-4b0a-9597-e0c49df797b6"},"source":["train_dataset.columns = ['ctext','text']\n","train_dataset.ctext = 'summarize: ' + train_dataset.ctext\n","\n","training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","\n","training_loader = DataLoader(training_set, **train_params)\n","\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n","for epoch in range(config.TRAIN_EPOCHS):\n","    print (1)\n","    train(epoch, tokenizer, model, device, training_loader, optimizer)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.3987181186676025\n"]},{"output_type":"stream","name":"stderr","text":["500it [03:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.6456035375595093\n"]},{"output_type":"stream","name":"stderr","text":["1000it [07:35,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5580538511276245\n"]},{"output_type":"stream","name":"stderr","text":["1500it [11:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.3609187602996826\n"]},{"output_type":"stream","name":"stderr","text":["2000it [15:09,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.629923105239868\n"]},{"output_type":"stream","name":"stderr","text":["2500it [18:57,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.8724935054779053\n"]},{"output_type":"stream","name":"stderr","text":["3000it [22:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.7859203815460205\n"]},{"output_type":"stream","name":"stderr","text":["3500it [26:31,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.421891689300537\n"]},{"output_type":"stream","name":"stderr","text":["4000it [30:18,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.471557378768921\n"]},{"output_type":"stream","name":"stderr","text":["4500it [34:06,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.1197545528411865\n"]},{"output_type":"stream","name":"stderr","text":["5000it [37:53,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7624073028564453\n"]},{"output_type":"stream","name":"stderr","text":["5500it [41:40,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5825008153915405\n"]},{"output_type":"stream","name":"stderr","text":["6000it [45:28,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7858902215957642\n"]},{"output_type":"stream","name":"stderr","text":["6500it [49:15,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.882528305053711\n"]},{"output_type":"stream","name":"stderr","text":["7000it [53:02,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5564007759094238\n"]},{"output_type":"stream","name":"stderr","text":["7500it [56:49,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.4423627853393555\n"]},{"output_type":"stream","name":"stderr","text":["8000it [1:00:37,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5779095888137817\n"]},{"output_type":"stream","name":"stderr","text":["8500it [1:04:24,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  0.9346849322319031\n"]},{"output_type":"stream","name":"stderr","text":["9000it [1:08:11,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.2886693477630615\n"]},{"output_type":"stream","name":"stderr","text":["9500it [1:11:59,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.3018906116485596\n"]},{"output_type":"stream","name":"stderr","text":["10000it [1:15:46,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7987236976623535\n"]},{"output_type":"stream","name":"stderr","text":["10500it [1:19:33,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.3024380207061768\n"]},{"output_type":"stream","name":"stderr","text":["11000it [1:23:20,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  3.072810173034668\n"]},{"output_type":"stream","name":"stderr","text":["11500it [1:27:08,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.9073739051818848\n"]},{"output_type":"stream","name":"stderr","text":["12000it [1:30:55,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.2263882160186768\n"]},{"output_type":"stream","name":"stderr","text":["12500it [1:34:42,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.3519108295440674\n"]},{"output_type":"stream","name":"stderr","text":["13000it [1:38:29,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.0130047798156738\n"]},{"output_type":"stream","name":"stderr","text":["13500it [1:42:17,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.127835750579834\n"]},{"output_type":"stream","name":"stderr","text":["14000it [1:46:04,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.2579761743545532\n"]},{"output_type":"stream","name":"stderr","text":["14500it [1:49:51,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5114823579788208\n"]},{"output_type":"stream","name":"stderr","text":["15000it [1:53:38,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.4316943883895874\n"]},{"output_type":"stream","name":"stderr","text":["15500it [1:57:26,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.1874678134918213\n"]},{"output_type":"stream","name":"stderr","text":["16000it [2:01:13,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7518097162246704\n"]},{"output_type":"stream","name":"stderr","text":["16500it [2:05:00,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7713080644607544\n"]},{"output_type":"stream","name":"stderr","text":["17000it [2:08:48,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.4326754808425903\n"]},{"output_type":"stream","name":"stderr","text":["17500it [2:12:35,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.2962796688079834\n"]},{"output_type":"stream","name":"stderr","text":["18000it [2:16:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.0990716218948364\n"]},{"output_type":"stream","name":"stderr","text":["18500it [2:20:10,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.689166784286499\n"]},{"output_type":"stream","name":"stderr","text":["19000it [2:23:57,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.474741816520691\n"]},{"output_type":"stream","name":"stderr","text":["19500it [2:27:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.1180033683776855\n"]},{"output_type":"stream","name":"stderr","text":["20000it [2:31:31,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.1344265937805176\n"]},{"output_type":"stream","name":"stderr","text":["20500it [2:35:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.5911550521850586\n"]},{"output_type":"stream","name":"stderr","text":["21000it [2:39:06,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5825965404510498\n"]},{"output_type":"stream","name":"stderr","text":["21500it [2:42:53,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.0459240674972534\n"]},{"output_type":"stream","name":"stderr","text":["22000it [2:46:41,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.3186216354370117\n"]},{"output_type":"stream","name":"stderr","text":["22500it [2:50:28,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5832439661026\n"]},{"output_type":"stream","name":"stderr","text":["23000it [2:54:15,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.834171175956726\n"]},{"output_type":"stream","name":"stderr","text":["23500it [2:58:03,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5514020919799805\n"]},{"output_type":"stream","name":"stderr","text":["24000it [3:01:50,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.2421531677246094\n"]},{"output_type":"stream","name":"stderr","text":["24500it [3:05:37,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.2403528690338135\n"]},{"output_type":"stream","name":"stderr","text":["25000it [3:09:25,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.4454962015151978\n"]},{"output_type":"stream","name":"stderr","text":["25500it [3:13:12,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  3.2437663078308105\n"]},{"output_type":"stream","name":"stderr","text":["26000it [3:16:59,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.801901340484619\n"]},{"output_type":"stream","name":"stderr","text":["26500it [3:20:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5885658264160156\n"]},{"output_type":"stream","name":"stderr","text":["27000it [3:24:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.005044937133789\n"]},{"output_type":"stream","name":"stderr","text":["27500it [3:28:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.290026903152466\n"]},{"output_type":"stream","name":"stderr","text":["28000it [3:32:08,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.255347728729248\n"]},{"output_type":"stream","name":"stderr","text":["28500it [3:35:56,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.1684184074401855\n"]},{"output_type":"stream","name":"stderr","text":["29000it [3:39:43,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.4991143941879272\n"]},{"output_type":"stream","name":"stderr","text":["29500it [3:43:30,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.0947476625442505\n"]},{"output_type":"stream","name":"stderr","text":["30000it [3:47:17,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.2716505527496338\n"]},{"output_type":"stream","name":"stderr","text":["30500it [3:51:05,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.251180648803711\n"]},{"output_type":"stream","name":"stderr","text":["31000it [3:54:52,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  0.9187946915626526\n"]},{"output_type":"stream","name":"stderr","text":["31500it [3:58:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.626493453979492\n"]},{"output_type":"stream","name":"stderr","text":["32000it [4:02:27,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.049684762954712\n"]},{"output_type":"stream","name":"stderr","text":["32500it [4:06:14,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.910247564315796\n"]},{"output_type":"stream","name":"stderr","text":["33000it [4:10:01,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.2852050065994263\n"]},{"output_type":"stream","name":"stderr","text":["33500it [4:13:49,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.205699920654297\n"]},{"output_type":"stream","name":"stderr","text":["34000it [4:17:36,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.54995596408844\n"]},{"output_type":"stream","name":"stderr","text":["34500it [4:21:23,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.7695188522338867\n"]},{"output_type":"stream","name":"stderr","text":["35000it [4:25:10,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.18449330329895\n"]},{"output_type":"stream","name":"stderr","text":["35500it [4:28:58,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  0.967880129814148\n"]},{"output_type":"stream","name":"stderr","text":["36000it [4:32:45,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5295064449310303\n"]},{"output_type":"stream","name":"stderr","text":["36500it [4:36:32,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5800466537475586\n"]},{"output_type":"stream","name":"stderr","text":["37000it [4:40:20,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5124958753585815\n"]},{"output_type":"stream","name":"stderr","text":["37500it [4:44:07,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.9511066675186157\n"]},{"output_type":"stream","name":"stderr","text":["38000it [4:47:54,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.1714915037155151\n"]},{"output_type":"stream","name":"stderr","text":["38500it [4:51:42,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.1586008071899414\n"]},{"output_type":"stream","name":"stderr","text":["39000it [4:55:29,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.019223928451538\n"]},{"output_type":"stream","name":"stderr","text":["39500it [4:59:16,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.350661516189575\n"]},{"output_type":"stream","name":"stderr","text":["40000it [5:03:03,  2.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3173236846923828\n"]},{"output_type":"stream","name":"stderr","text":["500it [03:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.9571117758750916\n"]},{"output_type":"stream","name":"stderr","text":["1000it [07:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.573488473892212\n"]},{"output_type":"stream","name":"stderr","text":["1500it [11:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4687732458114624\n"]},{"output_type":"stream","name":"stderr","text":["2000it [15:09,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.6248092651367188\n"]},{"output_type":"stream","name":"stderr","text":["2500it [18:56,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3127108812332153\n"]},{"output_type":"stream","name":"stderr","text":["3000it [22:43,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.9195072650909424\n"]},{"output_type":"stream","name":"stderr","text":["3500it [26:30,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.0457737445831299\n"]},{"output_type":"stream","name":"stderr","text":["4000it [30:18,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.5911380648612976\n"]},{"output_type":"stream","name":"stderr","text":["4500it [34:05,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.253279685974121\n"]},{"output_type":"stream","name":"stderr","text":["5000it [37:52,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.415119171142578\n"]},{"output_type":"stream","name":"stderr","text":["5500it [41:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2700849771499634\n"]},{"output_type":"stream","name":"stderr","text":["6000it [45:27,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.27133047580719\n"]},{"output_type":"stream","name":"stderr","text":["6500it [49:14,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.6660839319229126\n"]},{"output_type":"stream","name":"stderr","text":["7000it [53:01,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.39567232131958\n"]},{"output_type":"stream","name":"stderr","text":["7500it [56:48,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.0214955806732178\n"]},{"output_type":"stream","name":"stderr","text":["8000it [1:00:36,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.5997747778892517\n"]},{"output_type":"stream","name":"stderr","text":["8500it [1:04:23,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.6939074993133545\n"]},{"output_type":"stream","name":"stderr","text":["9000it [1:08:10,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2086533308029175\n"]},{"output_type":"stream","name":"stderr","text":["9500it [1:11:58,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3324779272079468\n"]},{"output_type":"stream","name":"stderr","text":["10000it [1:15:45,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1275265216827393\n"]},{"output_type":"stream","name":"stderr","text":["10500it [1:19:32,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.501990556716919\n"]},{"output_type":"stream","name":"stderr","text":["11000it [1:23:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3212107419967651\n"]},{"output_type":"stream","name":"stderr","text":["11500it [1:27:07,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4857056140899658\n"]},{"output_type":"stream","name":"stderr","text":["12000it [1:30:54,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.034682273864746\n"]},{"output_type":"stream","name":"stderr","text":["12500it [1:34:41,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.399649739265442\n"]},{"output_type":"stream","name":"stderr","text":["13000it [1:38:28,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.286468029022217\n"]},{"output_type":"stream","name":"stderr","text":["13500it [1:42:16,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.5639433860778809\n"]},{"output_type":"stream","name":"stderr","text":["14000it [1:46:03,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.6967484951019287\n"]},{"output_type":"stream","name":"stderr","text":["14500it [1:49:50,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1802849769592285\n"]},{"output_type":"stream","name":"stderr","text":["15000it [1:53:37,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.0015901327133179\n"]},{"output_type":"stream","name":"stderr","text":["15500it [1:57:25,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2628871202468872\n"]},{"output_type":"stream","name":"stderr","text":["16000it [2:01:12,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.100254774093628\n"]},{"output_type":"stream","name":"stderr","text":["16500it [2:04:59,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.5304659605026245\n"]},{"output_type":"stream","name":"stderr","text":["17000it [2:08:46,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.7757562398910522\n"]},{"output_type":"stream","name":"stderr","text":["17500it [2:12:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.3064253330230713\n"]},{"output_type":"stream","name":"stderr","text":["18000it [2:16:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.432669162750244\n"]},{"output_type":"stream","name":"stderr","text":["18500it [2:20:08,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.0155491828918457\n"]},{"output_type":"stream","name":"stderr","text":["19000it [2:23:55,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.625312089920044\n"]},{"output_type":"stream","name":"stderr","text":["19500it [2:27:43,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.681203007698059\n"]},{"output_type":"stream","name":"stderr","text":["20000it [2:31:30,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.9146013259887695\n"]},{"output_type":"stream","name":"stderr","text":["20500it [2:35:17,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.6851942539215088\n"]},{"output_type":"stream","name":"stderr","text":["21000it [2:39:04,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.5279786586761475\n"]},{"output_type":"stream","name":"stderr","text":["21500it [2:42:52,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.9131944179534912\n"]},{"output_type":"stream","name":"stderr","text":["22000it [2:46:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.6845773458480835\n"]},{"output_type":"stream","name":"stderr","text":["22500it [2:50:26,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.6604349613189697\n"]},{"output_type":"stream","name":"stderr","text":["23000it [2:54:13,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.179659605026245\n"]},{"output_type":"stream","name":"stderr","text":["23500it [2:58:00,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.7882250547409058\n"]},{"output_type":"stream","name":"stderr","text":["24000it [3:01:48,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.5523072481155396\n"]},{"output_type":"stream","name":"stderr","text":["24500it [3:05:35,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.280229091644287\n"]},{"output_type":"stream","name":"stderr","text":["25000it [3:09:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.382956027984619\n"]},{"output_type":"stream","name":"stderr","text":["25500it [3:13:09,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.839860200881958\n"]},{"output_type":"stream","name":"stderr","text":["26000it [3:16:56,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.6083402633666992\n"]},{"output_type":"stream","name":"stderr","text":["26500it [3:20:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.302046775817871\n"]},{"output_type":"stream","name":"stderr","text":["27000it [3:24:31,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1542826890945435\n"]},{"output_type":"stream","name":"stderr","text":["27500it [3:28:18,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3432672023773193\n"]},{"output_type":"stream","name":"stderr","text":["28000it [3:32:05,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.5768089294433594\n"]},{"output_type":"stream","name":"stderr","text":["28500it [3:35:53,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  3.3259329795837402\n"]},{"output_type":"stream","name":"stderr","text":["29000it [3:39:40,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.2493667602539062\n"]},{"output_type":"stream","name":"stderr","text":["29500it [3:43:27,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.9511299133300781\n"]},{"output_type":"stream","name":"stderr","text":["30000it [3:47:14,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.2862319946289062\n"]},{"output_type":"stream","name":"stderr","text":["30500it [3:51:01,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2922208309173584\n"]},{"output_type":"stream","name":"stderr","text":["31000it [3:54:49,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4987581968307495\n"]},{"output_type":"stream","name":"stderr","text":["31500it [3:58:36,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.9583263397216797\n"]},{"output_type":"stream","name":"stderr","text":["32000it [4:02:23,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.5909746885299683\n"]},{"output_type":"stream","name":"stderr","text":["32500it [4:06:10,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.42056143283844\n"]},{"output_type":"stream","name":"stderr","text":["33000it [4:09:58,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.5713776350021362\n"]},{"output_type":"stream","name":"stderr","text":["33500it [4:13:45,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4113070964813232\n"]},{"output_type":"stream","name":"stderr","text":["34000it [4:17:32,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2379732131958008\n"]},{"output_type":"stream","name":"stderr","text":["34500it [4:21:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3679543733596802\n"]},{"output_type":"stream","name":"stderr","text":["35000it [4:25:07,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.3668365478515625\n"]},{"output_type":"stream","name":"stderr","text":["35500it [4:28:54,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.7363587617874146\n"]},{"output_type":"stream","name":"stderr","text":["36000it [4:32:41,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.0331366062164307\n"]},{"output_type":"stream","name":"stderr","text":["36500it [4:36:29,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.7528792023658752\n"]},{"output_type":"stream","name":"stderr","text":["37000it [4:40:16,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1195366382598877\n"]},{"output_type":"stream","name":"stderr","text":["37500it [4:44:03,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3119779825210571\n"]},{"output_type":"stream","name":"stderr","text":["38000it [4:47:50,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.38015079498291\n"]},{"output_type":"stream","name":"stderr","text":["38500it [4:51:38,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.667981505393982\n"]},{"output_type":"stream","name":"stderr","text":["39000it [4:55:25,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.9791065454483032\n"]},{"output_type":"stream","name":"stderr","text":["39500it [4:59:12,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3342714309692383\n"]},{"output_type":"stream","name":"stderr","text":["40000it [5:02:59,  2.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.324553370475769\n"]},{"output_type":"stream","name":"stderr","text":["500it [03:47,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.015872597694397\n"]},{"output_type":"stream","name":"stderr","text":["1000it [07:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.347111940383911\n"]},{"output_type":"stream","name":"stderr","text":["1500it [11:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.409080982208252\n"]},{"output_type":"stream","name":"stderr","text":["2000it [15:08,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.805763602256775\n"]},{"output_type":"stream","name":"stderr","text":["2500it [18:56,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.6712582111358643\n"]},{"output_type":"stream","name":"stderr","text":["3000it [22:43,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.188211441040039\n"]},{"output_type":"stream","name":"stderr","text":["3500it [26:30,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0139482021331787\n"]},{"output_type":"stream","name":"stderr","text":["4000it [30:18,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.459555983543396\n"]},{"output_type":"stream","name":"stderr","text":["4500it [34:05,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4373252391815186\n"]},{"output_type":"stream","name":"stderr","text":["5000it [37:52,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.6360855102539062\n"]},{"output_type":"stream","name":"stderr","text":["5500it [41:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.5825343132019043\n"]},{"output_type":"stream","name":"stderr","text":["6000it [45:26,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.419691324234009\n"]},{"output_type":"stream","name":"stderr","text":["6500it [49:14,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.2636911869049072\n"]},{"output_type":"stream","name":"stderr","text":["7000it [53:01,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  3.1782140731811523\n"]},{"output_type":"stream","name":"stderr","text":["7500it [56:48,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.535415530204773\n"]},{"output_type":"stream","name":"stderr","text":["8000it [1:00:35,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.1653802394866943\n"]},{"output_type":"stream","name":"stderr","text":["8500it [1:04:23,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0767977237701416\n"]},{"output_type":"stream","name":"stderr","text":["9000it [1:08:10,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.914114236831665\n"]},{"output_type":"stream","name":"stderr","text":["9500it [1:11:57,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.458412766456604\n"]},{"output_type":"stream","name":"stderr","text":["10000it [1:15:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.7600892782211304\n"]},{"output_type":"stream","name":"stderr","text":["10500it [1:19:32,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.539467692375183\n"]},{"output_type":"stream","name":"stderr","text":["11000it [1:23:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.163225531578064\n"]},{"output_type":"stream","name":"stderr","text":["11500it [1:27:06,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.969792127609253\n"]},{"output_type":"stream","name":"stderr","text":["12000it [1:30:54,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.9485548734664917\n"]},{"output_type":"stream","name":"stderr","text":["12500it [1:34:41,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.3395941257476807\n"]},{"output_type":"stream","name":"stderr","text":["13000it [1:38:28,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.460916519165039\n"]},{"output_type":"stream","name":"stderr","text":["13500it [1:42:16,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.610754370689392\n"]},{"output_type":"stream","name":"stderr","text":["14000it [1:46:03,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.2139418125152588\n"]},{"output_type":"stream","name":"stderr","text":["14500it [1:49:50,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.6805928945541382\n"]},{"output_type":"stream","name":"stderr","text":["15000it [1:53:38,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.5493336915969849\n"]},{"output_type":"stream","name":"stderr","text":["15500it [1:57:25,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.156909465789795\n"]},{"output_type":"stream","name":"stderr","text":["16000it [2:01:13,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.2189483642578125\n"]},{"output_type":"stream","name":"stderr","text":["16500it [2:05:00,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0448857545852661\n"]},{"output_type":"stream","name":"stderr","text":["17000it [2:08:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.7734133005142212\n"]},{"output_type":"stream","name":"stderr","text":["17500it [2:12:35,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0317857265472412\n"]},{"output_type":"stream","name":"stderr","text":["18000it [2:16:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.9206682443618774\n"]},{"output_type":"stream","name":"stderr","text":["18500it [2:20:09,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.4509851932525635\n"]},{"output_type":"stream","name":"stderr","text":["19000it [2:23:57,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.6617575883865356\n"]},{"output_type":"stream","name":"stderr","text":["19500it [2:27:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.5211366415023804\n"]},{"output_type":"stream","name":"stderr","text":["20000it [2:31:32,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.104844808578491\n"]},{"output_type":"stream","name":"stderr","text":["20500it [2:35:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.2831759452819824\n"]},{"output_type":"stream","name":"stderr","text":["21000it [2:39:06,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.120972156524658\n"]},{"output_type":"stream","name":"stderr","text":["21500it [2:42:54,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.6966933012008667\n"]},{"output_type":"stream","name":"stderr","text":["22000it [2:46:41,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.732949137687683\n"]},{"output_type":"stream","name":"stderr","text":["22500it [2:50:28,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.1053853034973145\n"]},{"output_type":"stream","name":"stderr","text":["23000it [2:54:16,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.9518864154815674\n"]},{"output_type":"stream","name":"stderr","text":["23500it [2:58:03,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.38753342628479\n"]},{"output_type":"stream","name":"stderr","text":["24000it [3:01:50,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0521962642669678\n"]},{"output_type":"stream","name":"stderr","text":["24500it [3:05:37,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.5913238525390625\n"]},{"output_type":"stream","name":"stderr","text":["25000it [3:09:25,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.6531203985214233\n"]},{"output_type":"stream","name":"stderr","text":["25500it [3:13:12,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.664349913597107\n"]},{"output_type":"stream","name":"stderr","text":["26000it [3:17:00,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.5917590856552124\n"]},{"output_type":"stream","name":"stderr","text":["26500it [3:20:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4636874198913574\n"]},{"output_type":"stream","name":"stderr","text":["27000it [3:24:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.120924472808838\n"]},{"output_type":"stream","name":"stderr","text":["27500it [3:28:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4348433017730713\n"]},{"output_type":"stream","name":"stderr","text":["28000it [3:32:09,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.8952805995941162\n"]},{"output_type":"stream","name":"stderr","text":["28500it [3:35:56,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.6849442720413208\n"]},{"output_type":"stream","name":"stderr","text":["29000it [3:39:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.2872376441955566\n"]},{"output_type":"stream","name":"stderr","text":["29500it [3:43:31,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.7241682410240173\n"]},{"output_type":"stream","name":"stderr","text":["30000it [3:47:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.6182352304458618\n"]},{"output_type":"stream","name":"stderr","text":["30500it [3:51:06,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.1210746765136719\n"]},{"output_type":"stream","name":"stderr","text":["31000it [3:54:53,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.876590371131897\n"]},{"output_type":"stream","name":"stderr","text":["31500it [3:58:41,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.9195443391799927\n"]},{"output_type":"stream","name":"stderr","text":["32000it [4:02:28,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.5210812091827393\n"]},{"output_type":"stream","name":"stderr","text":["32500it [4:06:15,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  3.334210157394409\n"]},{"output_type":"stream","name":"stderr","text":["33000it [4:10:03,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4413025379180908\n"]},{"output_type":"stream","name":"stderr","text":["33500it [4:13:50,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.11374831199646\n"]},{"output_type":"stream","name":"stderr","text":["34000it [4:17:38,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.70260488986969\n"]},{"output_type":"stream","name":"stderr","text":["34500it [4:21:25,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4972717761993408\n"]},{"output_type":"stream","name":"stderr","text":["35000it [4:25:12,  2.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.7415666580200195\n"]},{"output_type":"stream","name":"stderr","text":["35500it [4:29:00,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.1935490369796753\n"]},{"output_type":"stream","name":"stderr","text":["36000it [4:32:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.7175874710083008\n"]},{"output_type":"stream","name":"stderr","text":["36500it [4:36:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.8099113702774048\n"]},{"output_type":"stream","name":"stderr","text":["37000it [4:40:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.0611424446105957\n"]},{"output_type":"stream","name":"stderr","text":["37500it [4:44:09,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4638088941574097\n"]},{"output_type":"stream","name":"stderr","text":["38000it [4:47:56,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.966881513595581\n"]},{"output_type":"stream","name":"stderr","text":["38500it [4:51:44,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.6545860767364502\n"]},{"output_type":"stream","name":"stderr","text":["39000it [4:55:31,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.2134946584701538\n"]},{"output_type":"stream","name":"stderr","text":["39500it [4:59:19,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.045651435852051\n"]},{"output_type":"stream","name":"stderr","text":["40000it [5:03:06,  2.20it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"EIdUCIseuQ18","executionInfo":{"status":"ok","timestamp":1638286797115,"user_tz":-540,"elapsed":4099,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["tokenizer.save_pretrained('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/2차')\n","model.save_pretrained('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/2차')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":493},"id":"79OKHJsVzRyI","executionInfo":{"status":"error","timestamp":1638286801991,"user_tz":-540,"elapsed":4881,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"2e9d8ab6-5243-4d67-a307-388059a6dc26"},"source":["validation_dataset.columns = ['ctext','text']\n","validation_dataset.ctext = 'summarize: ' + validation_dataset.ctext\n","\n","val_set = CustomDataset(validation_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","\n","val_loader = DataLoader(val_set, **val_params)\n","\n","for epoch in range(config.VAL_EPOCHS):\n","    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n","    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n","\n","final_df"],"execution_count":22,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: 0 is not in range","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-d972df2bb122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAL_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactuals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Generated Text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Actual Text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-e5489420ad25>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(epoch, tokenizer, model, device, loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mactuals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-c190a5d0620c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mctext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mctext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 0"]}]},{"cell_type":"code","metadata":{"id":"wpXjtG_RzStO","executionInfo":{"status":"aborted","timestamp":1638286799855,"user_tz":-540,"elapsed":2309,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["final_df.to_csv('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/ke-t5_ver2.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kdNqhV77ugX6","executionInfo":{"status":"ok","timestamp":1638312488212,"user_tz":-540,"elapsed":13981,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["from transformers import T5Tokenizer, T5ForConditionalGeneration\n","from tqdm import tqdm\n","import torch\n","from torch.utils.data import DataLoader\n","\n","\n","model_folder = '/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/2차'\n","\n","model = T5ForConditionalGeneration.from_pretrained(model_folder)\n","tokenizer = T5Tokenizer.from_pretrained(model_folder)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"VBNWpmXeww2k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638312536102,"user_tz":-540,"elapsed":11535,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"607bddce-7955-4595-cbab-a34c34bd0955"},"source":["model.to(device)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(64128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(64128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(64128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=64128, bias=False)\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"waJcdUlHwxcE","executionInfo":{"status":"ok","timestamp":1638312536103,"user_tz":-540,"elapsed":3,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["train_params = {\n","        'batch_size': config.TRAIN_BATCH_SIZE,\n","        'shuffle': True,\n","        'num_workers': 0\n","        }\n","\n","val_params = {\n","        'batch_size': config.VALID_BATCH_SIZE,\n","        'shuffle': False,\n","        'num_workers': 0\n","        }\n","\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"6LiXTCVJzgrq","executionInfo":{"status":"ok","timestamp":1638312543054,"user_tz":-540,"elapsed":6954,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["import pandas as pd\n","train_dataset = pd.read_csv('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/dataset for test/third.csv')[['document','label']]\n","validation_dataset = pd.read_csv('/content/drive/MyDrive/3차 프로젝트/dataset/valid.csv')[['document','label']]"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyBidbVwuSKW","executionInfo":{"status":"ok","timestamp":1638312543054,"user_tz":-540,"elapsed":18,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["import numpy as np\n","\n","train_dataset1 = train_dataset\n","validation_dataset = validation_dataset[2000:3000]"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnFkJFDFuWY_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638330328353,"user_tz":-540,"elapsed":17780913,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"79002cc3-aca4-42b7-f2f0-76b7c4d77ec3"},"source":["train_dataset.columns = ['ctext','text']\n","train_dataset.ctext = 'summarize: ' + train_dataset.ctext\n","\n","training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","\n","training_loader = DataLoader(training_set, **train_params)\n","\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n","for epoch in range(config.TRAIN_EPOCHS):\n","    print (1)\n","    train(epoch, tokenizer, model, device, training_loader, optimizer)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.353576898574829\n"]},{"output_type":"stream","name":"stderr","text":["500it [03:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.4606157541275024\n"]},{"output_type":"stream","name":"stderr","text":["1000it [07:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.3727660179138184\n"]},{"output_type":"stream","name":"stderr","text":["1500it [11:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.45961594581604\n"]},{"output_type":"stream","name":"stderr","text":["2000it [15:08,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.3122247457504272\n"]},{"output_type":"stream","name":"stderr","text":["2500it [18:55,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.6847774982452393\n"]},{"output_type":"stream","name":"stderr","text":["3000it [22:43,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.3220723867416382\n"]},{"output_type":"stream","name":"stderr","text":["3500it [26:30,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  0.997904896736145\n"]},{"output_type":"stream","name":"stderr","text":["4000it [30:17,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  0.7138233184814453\n"]},{"output_type":"stream","name":"stderr","text":["4500it [34:04,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  0.7504770159721375\n"]},{"output_type":"stream","name":"stderr","text":["5000it [37:51,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.3605825901031494\n"]},{"output_type":"stream","name":"stderr","text":["5500it [41:38,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.3826144933700562\n"]},{"output_type":"stream","name":"stderr","text":["6000it [45:25,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.431179165840149\n"]},{"output_type":"stream","name":"stderr","text":["6500it [49:13,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.6531728506088257\n"]},{"output_type":"stream","name":"stderr","text":["7000it [53:00,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.4553344249725342\n"]},{"output_type":"stream","name":"stderr","text":["7500it [56:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7181556224822998\n"]},{"output_type":"stream","name":"stderr","text":["8000it [1:00:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.0821638107299805\n"]},{"output_type":"stream","name":"stderr","text":["8500it [1:04:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5770660638809204\n"]},{"output_type":"stream","name":"stderr","text":["9000it [1:08:08,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.1414252519607544\n"]},{"output_type":"stream","name":"stderr","text":["9500it [1:11:55,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.157622814178467\n"]},{"output_type":"stream","name":"stderr","text":["10000it [1:15:43,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.874360203742981\n"]},{"output_type":"stream","name":"stderr","text":["10500it [1:19:30,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.153611421585083\n"]},{"output_type":"stream","name":"stderr","text":["11000it [1:23:17,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  0.8209546208381653\n"]},{"output_type":"stream","name":"stderr","text":["11500it [1:27:04,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.560614824295044\n"]},{"output_type":"stream","name":"stderr","text":["12000it [1:30:51,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.059051036834717\n"]},{"output_type":"stream","name":"stderr","text":["12500it [1:34:38,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.2603306770324707\n"]},{"output_type":"stream","name":"stderr","text":["13000it [1:38:25,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.9203410148620605\n"]},{"output_type":"stream","name":"stderr","text":["13045it [1:38:46,  2.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4410791397094727\n"]},{"output_type":"stream","name":"stderr","text":["500it [03:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.584540605545044\n"]},{"output_type":"stream","name":"stderr","text":["1000it [07:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1545177698135376\n"]},{"output_type":"stream","name":"stderr","text":["1500it [11:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.8886930346488953\n"]},{"output_type":"stream","name":"stderr","text":["2000it [15:08,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.8661904335021973\n"]},{"output_type":"stream","name":"stderr","text":["2500it [18:55,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2936985492706299\n"]},{"output_type":"stream","name":"stderr","text":["3000it [22:42,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.3472790718078613\n"]},{"output_type":"stream","name":"stderr","text":["3500it [26:30,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.4517223834991455\n"]},{"output_type":"stream","name":"stderr","text":["4000it [30:17,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.632280707359314\n"]},{"output_type":"stream","name":"stderr","text":["4500it [34:04,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.0796048641204834\n"]},{"output_type":"stream","name":"stderr","text":["5000it [37:51,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3163682222366333\n"]},{"output_type":"stream","name":"stderr","text":["5500it [41:38,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.0756654739379883\n"]},{"output_type":"stream","name":"stderr","text":["6000it [45:25,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.650829553604126\n"]},{"output_type":"stream","name":"stderr","text":["6500it [49:13,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.465813398361206\n"]},{"output_type":"stream","name":"stderr","text":["7000it [53:00,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1974002122879028\n"]},{"output_type":"stream","name":"stderr","text":["7500it [56:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.499532699584961\n"]},{"output_type":"stream","name":"stderr","text":["8000it [1:00:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.253310441970825\n"]},{"output_type":"stream","name":"stderr","text":["8500it [1:04:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.896096408367157\n"]},{"output_type":"stream","name":"stderr","text":["9000it [1:08:08,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.6060023903846741\n"]},{"output_type":"stream","name":"stderr","text":["9500it [1:11:56,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.8751778602600098\n"]},{"output_type":"stream","name":"stderr","text":["10000it [1:15:43,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2581536769866943\n"]},{"output_type":"stream","name":"stderr","text":["10500it [1:19:30,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.3418300151824951\n"]},{"output_type":"stream","name":"stderr","text":["11000it [1:23:18,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.333618640899658\n"]},{"output_type":"stream","name":"stderr","text":["11500it [1:27:05,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.531172275543213\n"]},{"output_type":"stream","name":"stderr","text":["12000it [1:30:52,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.804404079914093\n"]},{"output_type":"stream","name":"stderr","text":["12500it [1:34:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.8515840768814087\n"]},{"output_type":"stream","name":"stderr","text":["13000it [1:38:26,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2916160821914673\n"]},{"output_type":"stream","name":"stderr","text":["13045it [1:38:47,  2.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.1839206218719482\n"]},{"output_type":"stream","name":"stderr","text":["500it [03:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.1530860662460327\n"]},{"output_type":"stream","name":"stderr","text":["1000it [07:34,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.5694779753684998\n"]},{"output_type":"stream","name":"stderr","text":["1500it [11:21,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.3533120155334473\n"]},{"output_type":"stream","name":"stderr","text":["2000it [15:08,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.8396661877632141\n"]},{"output_type":"stream","name":"stderr","text":["2500it [18:55,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.6417722702026367\n"]},{"output_type":"stream","name":"stderr","text":["3000it [22:43,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.6832281351089478\n"]},{"output_type":"stream","name":"stderr","text":["3500it [26:30,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.3733279705047607\n"]},{"output_type":"stream","name":"stderr","text":["4000it [30:17,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.8668838739395142\n"]},{"output_type":"stream","name":"stderr","text":["4500it [34:04,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.3739093542099\n"]},{"output_type":"stream","name":"stderr","text":["5000it [37:52,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0403085947036743\n"]},{"output_type":"stream","name":"stderr","text":["5500it [41:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4778339862823486\n"]},{"output_type":"stream","name":"stderr","text":["6000it [45:26,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.7214771509170532\n"]},{"output_type":"stream","name":"stderr","text":["6500it [49:13,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.3647948503494263\n"]},{"output_type":"stream","name":"stderr","text":["7000it [53:00,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.4305557012557983\n"]},{"output_type":"stream","name":"stderr","text":["7500it [56:47,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.5376057624816895\n"]},{"output_type":"stream","name":"stderr","text":["8000it [1:00:35,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.9893534779548645\n"]},{"output_type":"stream","name":"stderr","text":["8500it [1:04:22,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.0198845863342285\n"]},{"output_type":"stream","name":"stderr","text":["9000it [1:08:09,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.1720868349075317\n"]},{"output_type":"stream","name":"stderr","text":["9500it [1:11:56,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.017144799232483\n"]},{"output_type":"stream","name":"stderr","text":["10000it [1:15:43,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.9882003664970398\n"]},{"output_type":"stream","name":"stderr","text":["10500it [1:19:30,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.2242366075515747\n"]},{"output_type":"stream","name":"stderr","text":["11000it [1:23:18,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.2157329320907593\n"]},{"output_type":"stream","name":"stderr","text":["11500it [1:27:05,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.5796868801116943\n"]},{"output_type":"stream","name":"stderr","text":["12000it [1:30:52,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.790677785873413\n"]},{"output_type":"stream","name":"stderr","text":["12500it [1:34:39,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  2.540081739425659\n"]},{"output_type":"stream","name":"stderr","text":["13000it [1:38:26,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.8061035871505737\n"]},{"output_type":"stream","name":"stderr","text":["13045it [1:38:47,  2.20it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"VHRwXYPyuXUy","executionInfo":{"status":"ok","timestamp":1638330332615,"user_tz":-540,"elapsed":4287,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["tokenizer.save_pretrained('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/3차')\n","model.save_pretrained('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/3차')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"gT9Yt7nhG6-r","executionInfo":{"status":"ok","timestamp":1638330543521,"user_tz":-540,"elapsed":1516,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["validation_dataset = pd.read_csv('/content/drive/MyDrive/3차 프로젝트/dataset/valid.csv')[['document','label']]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"xgk4ZRHtPb2U","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1638349045945,"user_tz":-540,"elapsed":18498428,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}},"outputId":"cc9f521d-efbe-43f6-ceb9-0ab87f570d0a"},"source":["validation_dataset.columns = ['ctext','text']\n","validation_dataset.ctext = 'summarize: ' + validation_dataset.ctext\n","\n","val_set = CustomDataset(validation_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","\n","val_loader = DataLoader(val_set, **val_params)\n","\n","for epoch in range(config.VAL_EPOCHS):\n","    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n","    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n","\n","final_df"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Completed 0\n","Completed 100\n","Completed 200\n","Completed 300\n","Completed 400\n","Completed 500\n","Completed 600\n","Completed 700\n","Completed 800\n","Completed 900\n","Completed 1000\n","Completed 1100\n","Completed 1200\n","Completed 1300\n","Completed 1400\n","Completed 1500\n","Completed 1600\n","Completed 1700\n","Completed 1800\n","Completed 1900\n","Completed 2000\n","Completed 2100\n","Completed 2200\n","Completed 2300\n","Completed 2400\n","Completed 2500\n","Completed 2600\n","Completed 2700\n","Completed 2800\n","Completed 2900\n","Completed 3000\n","Completed 3100\n","Completed 3200\n","Completed 3300\n","Completed 3400\n","Completed 3500\n","Completed 3600\n","Completed 3700\n","Completed 3800\n","Completed 3900\n","Completed 4000\n","Completed 4100\n","Completed 4200\n","Completed 4300\n","Completed 4400\n","Completed 4500\n","Completed 4600\n","Completed 4700\n","Completed 4800\n","Completed 4900\n","Completed 5000\n","Completed 5100\n","Completed 5200\n","Completed 5300\n","Completed 5400\n","Completed 5500\n","Completed 5600\n","Completed 5700\n","Completed 5800\n","Completed 5900\n","Completed 6000\n","Completed 6100\n","Completed 6200\n","Completed 6300\n","Completed 6400\n","Completed 6500\n","Completed 6600\n","Completed 6700\n","Completed 6800\n","Completed 6900\n","Completed 7000\n","Completed 7100\n","Completed 7200\n","Completed 7300\n","Completed 7400\n","Completed 7500\n","Completed 7600\n","Completed 7700\n","Completed 7800\n","Completed 7900\n","Completed 8000\n","Completed 8100\n","Completed 8200\n","Completed 8300\n","Completed 8400\n","Completed 8500\n","Completed 8600\n","Completed 8700\n","Completed 8800\n","Completed 8900\n","Completed 9000\n","Completed 9100\n","Completed 9200\n","Completed 9300\n","Completed 9400\n","Completed 9500\n","Completed 9600\n","Completed 9700\n","Completed 9800\n","Completed 9900\n","Completed 10000\n","Completed 10100\n","Completed 10200\n","Completed 10300\n","Completed 10400\n","Completed 10500\n","Completed 10600\n","Completed 10700\n","Completed 10800\n","Completed 10900\n","Completed 11000\n","Completed 11100\n","Completed 11200\n","Completed 11300\n","Completed 11400\n","Completed 11500\n","Completed 11600\n","Completed 11700\n","Completed 11800\n","Completed 11900\n","Completed 12000\n","Completed 12100\n","Completed 12200\n","Completed 12300\n","Completed 12400\n","Completed 12500\n","Completed 12600\n","Completed 12700\n","Completed 12800\n","Completed 12900\n","Completed 13000\n","Completed 13100\n","Completed 13200\n","Completed 13300\n","Completed 13400\n","Completed 13500\n","Completed 13600\n","Completed 13700\n","Completed 13800\n","Completed 13900\n","Completed 14000\n","Completed 14100\n","Completed 14200\n","Completed 14300\n","Completed 14400\n","Completed 14500\n","Completed 14600\n","Completed 14700\n","Completed 14800\n","Completed 14900\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Generated Text</th>\n","      <th>Actual Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>큐브를 통해 악플러에 대한 강경대응을 예고하며 자체 모니터링을 강화하고 제보 전용 ...</td>\n","      <td>가수 강다니엘이 모욕죄 혐의로 악플러에 대한 고소장을 서울강남경찰서에 제출하며 합의...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>큐브 제1·2차 본회의를 열어 의장·부의장 및 상임위원장 선거를 실시한 '2019년...</td>\n","      <td>안산시의회는 지난 7월 22일과 29일에 청소년의회 제1·2차 본회의를 열어 실제 ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>큐브를 통해 출국을 하려다 긴급출국정지 조치로 일본으로 돌아가지 못한 일본인 A씨가...</td>\n","      <td>2019 광주세계수영선수권대회에서 18일 일본인A씨가 12명의 여자선수들의 신체 일...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>큐브와 외국어교육지원센터를 무료로 이용할 수 있는 '익산 오투그란데 글로벌카운티' ...</td>\n","      <td>제일건설은 실수요자들에게 선호도 높은 전용 면적과 효율적인 공간 활용을 강점으로 1...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>큐브 +14.87%, 148,300원, 한라IMS +3.15%, 7,210원, 케이...</td>\n","      <td>월요일 11시 00분 현재 조선업종 내 상승종목 등락률 1위를 차지한 에이치엘비종목...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>29995</th>\n","      <td>큐브와 별도로 'SK이노베이션 채용 사이트'를 개설해 운영중이며, 이번 경력채용에서...</td>\n","      <td>SK이노베이션은 김준 SK이노베이션 총괄 사장의 인재 영입 철학을 반영하여 작년 4...</td>\n","    </tr>\n","    <tr>\n","      <th>29996</th>\n","      <td>큐브에서 대학생 150명을 대상으로 취업 상담 기회를 제공하는 '상상 커리어다이닝'...</td>\n","      <td>내달 7일까지 KT&amp;G는 2~4학년 대학생 150명을 대상으로 취업 상담 프로그램 ...</td>\n","    </tr>\n","    <tr>\n","      <th>29997</th>\n","      <td>큐브 '백종원의 골목식당'이 조선업이 위기를 맞으며 지역 상권도 휘청이고 있는 '거...</td>\n","      <td>지난 27일 '백종원의 골목식당'은 '보리밥&amp;코다리찜'의 주방점검 장면에서 동시간대...</td>\n","    </tr>\n","    <tr>\n","      <th>29998</th>\n","      <td>큐브란 약 이름 속에 '마음을 맑게 가라앉혀 준다'는 효능이 담긴 우황(心)이란 약...</td>\n","      <td>소의 도축 과정에서 발견하여 약재로 쓰는 우황은 기본적으로 몸 안의 열을 치료하는 ...</td>\n","    </tr>\n","    <tr>\n","      <th>29999</th>\n","      <td>큐브 천정배 의원은 24일 국가보훈처로부터 ‘전두환 등 헌정질서파괴범은 사면·복권이...</td>\n","      <td>국가보훈처는 전두환 전 대통령이 사망하는 경우에도 전과사실이 실효되지 않아 국립묘지...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>30000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                          Generated Text                                        Actual Text\n","0      큐브를 통해 악플러에 대한 강경대응을 예고하며 자체 모니터링을 강화하고 제보 전용 ...  가수 강다니엘이 모욕죄 혐의로 악플러에 대한 고소장을 서울강남경찰서에 제출하며 합의...\n","1      큐브 제1·2차 본회의를 열어 의장·부의장 및 상임위원장 선거를 실시한 '2019년...  안산시의회는 지난 7월 22일과 29일에 청소년의회 제1·2차 본회의를 열어 실제 ...\n","2      큐브를 통해 출국을 하려다 긴급출국정지 조치로 일본으로 돌아가지 못한 일본인 A씨가...  2019 광주세계수영선수권대회에서 18일 일본인A씨가 12명의 여자선수들의 신체 일...\n","3      큐브와 외국어교육지원센터를 무료로 이용할 수 있는 '익산 오투그란데 글로벌카운티' ...  제일건설은 실수요자들에게 선호도 높은 전용 면적과 효율적인 공간 활용을 강점으로 1...\n","4      큐브 +14.87%, 148,300원, 한라IMS +3.15%, 7,210원, 케이...  월요일 11시 00분 현재 조선업종 내 상승종목 등락률 1위를 차지한 에이치엘비종목...\n","...                                                  ...                                                ...\n","29995  큐브와 별도로 'SK이노베이션 채용 사이트'를 개설해 운영중이며, 이번 경력채용에서...  SK이노베이션은 김준 SK이노베이션 총괄 사장의 인재 영입 철학을 반영하여 작년 4...\n","29996  큐브에서 대학생 150명을 대상으로 취업 상담 기회를 제공하는 '상상 커리어다이닝'...  내달 7일까지 KT&G는 2~4학년 대학생 150명을 대상으로 취업 상담 프로그램 ...\n","29997  큐브 '백종원의 골목식당'이 조선업이 위기를 맞으며 지역 상권도 휘청이고 있는 '거...  지난 27일 '백종원의 골목식당'은 '보리밥&코다리찜'의 주방점검 장면에서 동시간대...\n","29998  큐브란 약 이름 속에 '마음을 맑게 가라앉혀 준다'는 효능이 담긴 우황(心)이란 약...  소의 도축 과정에서 발견하여 약재로 쓰는 우황은 기본적으로 몸 안의 열을 치료하는 ...\n","29999  큐브 천정배 의원은 24일 국가보훈처로부터 ‘전두환 등 헌정질서파괴범은 사면·복권이...  국가보훈처는 전두환 전 대통령이 사망하는 경우에도 전과사실이 실효되지 않아 국립묘지...\n","\n","[30000 rows x 2 columns]"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"EHf3ue94bJzj","executionInfo":{"status":"ok","timestamp":1638349047662,"user_tz":-540,"elapsed":2,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":["final_df.to_csv('/content/drive/MyDrive/3차 프로젝트/KE-T5_JONGU/ke-t5_final3.csv')"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"YbYB5pz63uq-","executionInfo":{"status":"aborted","timestamp":1638129945495,"user_tz":-540,"elapsed":2171,"user":{"displayName":"이종현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03957334141941318645"}}},"source":[""],"execution_count":null,"outputs":[]}]}