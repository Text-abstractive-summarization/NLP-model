{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Etri_et5_train_(290000*10)_extra.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"23RcYKGZFSro"},"source":["참고 url : https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb"]},{"cell_type":"markdown","metadata":{"id":"f_YPosECYni1"},"source":["### version\n","train_data_size = 290000 (추가학습)   \n","batch_size = 2    \n","epochs = 10"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vH4DqQSdjq65","executionInfo":{"status":"ok","timestamp":1638717017638,"user_tz":-540,"elapsed":25486,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}},"outputId":"438ef0d9-372c-4888-ca4f-1d55a5791e3d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JR-heIHg7zJ4","executionInfo":{"status":"ok","timestamp":1638717037969,"user_tz":-540,"elapsed":10562,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}},"outputId":"612d5a37-3819-41d1-a21d-8c81b36f5b81"},"source":["!pip install transformers\n","!pip install sentencepiece==0.1.91"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 15.3 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 504 kB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 77.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 78.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 65.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n","Collecting sentencepiece==0.1.91\n","  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 15.2 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.91\n"]}]},{"cell_type":"markdown","metadata":{"id":"lPfEMbfCEo5u"},"source":["런타임 다시 시작 눌러야할 수 있음  \n","만일 tokenizer Nonetype 에러시 런타임 다시 시작"]},{"cell_type":"code","metadata":{"id":"V43hOR_o8t8Y","executionInfo":{"status":"ok","timestamp":1638717068449,"user_tz":-540,"elapsed":23839,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}}},"source":["# model.generate(pieces)\n","from transformers import T5Config, T5Tokenizer, T5ForConditionalGeneration\n","from tqdm import tqdm\n","import torch\n","from torch.utils.data import DataLoader\n","\n","\n","\n","model_folder = '/content/drive/MyDrive/cakd3_colab/3차 프로젝트/Etri_et5/Etri_et5_model_save/Etri_et5_model_save_(290000*10)_extra'\n","\n","model = T5ForConditionalGeneration.from_pretrained(model_folder)\n","tokenizer = T5Tokenizer.from_pretrained(model_folder)\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"e34lHWGtsSWd","executionInfo":{"status":"ok","timestamp":1638717068449,"user_tz":-540,"elapsed":3,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}}},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"LeNA2dpdtAVi","executionInfo":{"status":"ok","timestamp":1638717068449,"user_tz":-540,"elapsed":3,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}}},"source":["class CustomDataset:\n","\n","    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.source_len = source_len\n","        self.summ_len = summ_len\n","        self.text = self.data.text\n","        self.ctext = self.data.ctext\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        ctext = str(self.ctext[index])\n","        ctext = ' '.join(ctext.split())\n","\n","        text = str(self.text[index])\n","        text = ' '.join(text.split())\n","\n","        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n","        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n","\n","        source_ids = source['input_ids'].squeeze()\n","        source_mask = source['attention_mask'].squeeze()\n","        target_ids = target['input_ids'].squeeze()\n","        target_mask = target['attention_mask'].squeeze()\n","\n","        return {\n","            'source_ids': source_ids.to(dtype=torch.long), \n","            'source_mask': source_mask.to(dtype=torch.long), \n","            'target_ids': target_ids.to(dtype=torch.long),\n","            'target_ids_y': target_ids.to(dtype=torch.long)\n","        }"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcvmRVxasS_d","executionInfo":{"status":"ok","timestamp":1638717068449,"user_tz":-540,"elapsed":3,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}}},"source":["\n","\n","def train(epoch, tokenizer, model, device, loader, optimizer):\n","    model.train()\n","    for _,data in tqdm(enumerate(loader, 0)):\n","        y = data['target_ids'].to(device, dtype = torch.long)\n","        y_ids = y[:, :-1].contiguous()\n","        lm_labels = y[:, 1:].clone().detach()\n","        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n","        ids = data['source_ids'].to(device, dtype = torch.long)\n","        mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n","        loss = outputs[0]\n","        \n","        if _%10 == 0:\n","            pass\n","            \n","        if _%500==0:\n","            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # xm.optimizer_step(optimizer)\n","        # xm.mark_step()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ww9SpZIhsS8O","executionInfo":{"status":"ok","timestamp":1638717068450,"user_tz":-540,"elapsed":3,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}}},"source":["def validate(epoch, tokenizer, model, device, loader):\n","    model.eval()\n","    predictions = []\n","    actuals = []\n","    with torch.no_grad():\n","        for _, data in enumerate(loader, 0):\n","            y = data['target_ids'].to(device, dtype = torch.long)\n","            ids = data['source_ids'].to(device, dtype = torch.long)\n","            mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","            generated_ids = model.generate(\n","                input_ids = ids,\n","                attention_mask = mask, \n","                max_length=150, \n","                num_beams=2,\n","                repetition_penalty=2.5, \n","                length_penalty=1.0, \n","                early_stopping=True\n","                )\n","            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n","            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n","            if _%100==0:\n","                print(f'Completed {_}')\n","\n","            predictions.extend(preds)\n","            actuals.extend(target)\n","    return predictions, actuals"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Li1ZjzuosS5o","executionInfo":{"status":"ok","timestamp":1638717082158,"user_tz":-540,"elapsed":13711,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}},"outputId":"21414dd9-2866-4ecf-819c-7bfd4d206c95"},"source":["model.to(device)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(45100, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(45100, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(45100, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedGeluDense(\n","              (wi_0): Linear(in_features=768, out_features=3072, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=45100, bias=False)\n",")"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"-cE_KNFnjPF8"},"source":["hyper-parameters"]},{"cell_type":"code","metadata":{"id":"UbU1ySuJsS36","executionInfo":{"status":"ok","timestamp":1638717082158,"user_tz":-540,"elapsed":9,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}}},"source":["config = T5Config()\n","config.MAX_LEN = 1024\n","config.SUMMARY_LEN = 150 \n","config.TRAIN_BATCH_SIZE = 2    # input batch size for training (default: 64)\n","config.VALID_BATCH_SIZE = 2    # input batch size for testing (default: 1000)\n","config.TRAIN_EPOCHS = 10        # number of epochs to train (default: 10)\n","config.VAL_EPOCHS = 1 \n","config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n","config.SEED = 42               # random seed (default: 42)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hLshDtNsS1R","executionInfo":{"status":"ok","timestamp":1638717082158,"user_tz":-540,"elapsed":8,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}}},"source":["train_params = {\n","        'batch_size': config.TRAIN_BATCH_SIZE,\n","        'shuffle': True,\n","        'num_workers': 0\n","        }\n","\n","val_params = {\n","        'batch_size': config.VALID_BATCH_SIZE,\n","        'shuffle': False,\n","        'num_workers': 0\n","        }"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xrru0dvtxaWA","executionInfo":{"status":"ok","timestamp":1638598178920,"user_tz":-540,"elapsed":9,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}},"outputId":"d9dda6de-7791-40a4-c616-fe8cc1cd9b19"},"source":["!nvidia-smi\n"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Dec  4 06:09:38 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    39W / 300W |   3015MiB / 16160MiB |     26%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"1z5DClk92JFV","executionInfo":{"status":"ok","timestamp":1638717100177,"user_tz":-540,"elapsed":5403,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}}},"source":["import pandas as pd\n","train_dataset = pd.read_csv('/content/drive/MyDrive/3차 프로젝트/dataset/valid.csv')[['document','label']]\n","train_dataset = train_dataset.reset_index(drop=True).iloc[:20000]\n","validation_dataset = pd.read_csv('/content/drive/MyDrive/cakd3_colab/3차 프로젝트/dataset_split/valid_10000.csv')[['document','label']]"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x9dU3_h7jPF-"},"source":["Training model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U7e4LNJssSzF","executionInfo":{"status":"ok","timestamp":1638630546986,"user_tz":-540,"elapsed":32362936,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}},"outputId":"03fbb022-cf0c-48c6-d125-23fa20e978b7"},"source":["train_dataset.columns = ['ctext','text']\n","train_dataset.ctext = 'summarize: ' + train_dataset.ctext\n","\n","training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","\n","training_loader = DataLoader(training_set, **train_params)\n","\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n","for epoch in range(config.TRAIN_EPOCHS):\n","    print (1)\n","    train(epoch, tokenizer, model, device, training_loader, optimizer)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.8340139389038086\n"]},{"output_type":"stream","name":"stderr","text":["501it [02:42,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.8142222166061401\n"]},{"output_type":"stream","name":"stderr","text":["1001it [05:24,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.757716655731201\n"]},{"output_type":"stream","name":"stderr","text":["1501it [08:06,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.5708799362182617\n"]},{"output_type":"stream","name":"stderr","text":["2001it [10:48,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  3.153351068496704\n"]},{"output_type":"stream","name":"stderr","text":["2501it [13:30,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.353423833847046\n"]},{"output_type":"stream","name":"stderr","text":["3001it [16:12,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.306931495666504\n"]},{"output_type":"stream","name":"stderr","text":["3501it [18:55,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.515462875366211\n"]},{"output_type":"stream","name":"stderr","text":["4001it [21:37,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.191277503967285\n"]},{"output_type":"stream","name":"stderr","text":["4501it [24:19,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.192251205444336\n"]},{"output_type":"stream","name":"stderr","text":["5001it [27:01,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.7529938220977783\n"]},{"output_type":"stream","name":"stderr","text":["5501it [29:43,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.8509976863861084\n"]},{"output_type":"stream","name":"stderr","text":["6001it [32:25,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.3576178550720215\n"]},{"output_type":"stream","name":"stderr","text":["6501it [35:07,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.897709369659424\n"]},{"output_type":"stream","name":"stderr","text":["7001it [37:49,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.6174167394638062\n"]},{"output_type":"stream","name":"stderr","text":["7501it [40:31,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  2.344146728515625\n"]},{"output_type":"stream","name":"stderr","text":["8001it [43:13,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5506592988967896\n"]},{"output_type":"stream","name":"stderr","text":["8501it [45:56,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.8198497295379639\n"]},{"output_type":"stream","name":"stderr","text":["9001it [48:38,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.5141023397445679\n"]},{"output_type":"stream","name":"stderr","text":["9501it [51:19,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  1.7128453254699707\n"]},{"output_type":"stream","name":"stderr","text":["10000it [54:00,  3.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.508659839630127\n"]},{"output_type":"stream","name":"stderr","text":["501it [02:41,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.6454641222953796\n"]},{"output_type":"stream","name":"stderr","text":["1001it [05:23,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.8103737831115723\n"]},{"output_type":"stream","name":"stderr","text":["1501it [08:04,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.5847166776657104\n"]},{"output_type":"stream","name":"stderr","text":["2001it [10:46,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1299132108688354\n"]},{"output_type":"stream","name":"stderr","text":["2501it [13:27,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.309259295463562\n"]},{"output_type":"stream","name":"stderr","text":["3001it [16:08,  3.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.0618395805358887\n"]},{"output_type":"stream","name":"stderr","text":["3501it [18:50,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.6408851742744446\n"]},{"output_type":"stream","name":"stderr","text":["4001it [21:32,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.0101662874221802\n"]},{"output_type":"stream","name":"stderr","text":["4501it [24:13,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.495164394378662\n"]},{"output_type":"stream","name":"stderr","text":["5001it [26:55,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.2611058950424194\n"]},{"output_type":"stream","name":"stderr","text":["5501it [29:36,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1006349325180054\n"]},{"output_type":"stream","name":"stderr","text":["6001it [32:18,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.8316439390182495\n"]},{"output_type":"stream","name":"stderr","text":["6501it [34:59,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.0898845195770264\n"]},{"output_type":"stream","name":"stderr","text":["7001it [37:41,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.835790753364563\n"]},{"output_type":"stream","name":"stderr","text":["7501it [40:22,  3.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  0.6241466403007507\n"]},{"output_type":"stream","name":"stderr","text":["8001it [43:04,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.8969686031341553\n"]},{"output_type":"stream","name":"stderr","text":["8501it [45:45,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  2.2842891216278076\n"]},{"output_type":"stream","name":"stderr","text":["9001it [48:26,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.6458052396774292\n"]},{"output_type":"stream","name":"stderr","text":["9501it [51:08,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss:  1.1851884126663208\n"]},{"output_type":"stream","name":"stderr","text":["10000it [53:49,  3.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.7826158404350281\n"]},{"output_type":"stream","name":"stderr","text":["501it [02:41,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.987713634967804\n"]},{"output_type":"stream","name":"stderr","text":["1001it [05:22,  3.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.6734075546264648\n"]},{"output_type":"stream","name":"stderr","text":["1501it [08:04,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.30696168541908264\n"]},{"output_type":"stream","name":"stderr","text":["2001it [10:45,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.7797296643257141\n"]},{"output_type":"stream","name":"stderr","text":["2501it [13:25,  3.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.9512960314750671\n"]},{"output_type":"stream","name":"stderr","text":["3001it [16:07,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.904420018196106\n"]},{"output_type":"stream","name":"stderr","text":["3501it [18:48,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.684205949306488\n"]},{"output_type":"stream","name":"stderr","text":["4001it [21:29,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.5564295053482056\n"]},{"output_type":"stream","name":"stderr","text":["4501it [24:10,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.8890740275382996\n"]},{"output_type":"stream","name":"stderr","text":["5001it [26:51,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.4625236988067627\n"]},{"output_type":"stream","name":"stderr","text":["5501it [29:32,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.7407031655311584\n"]},{"output_type":"stream","name":"stderr","text":["6001it [32:14,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.8065962195396423\n"]},{"output_type":"stream","name":"stderr","text":["6501it [34:55,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.5899038314819336\n"]},{"output_type":"stream","name":"stderr","text":["7001it [37:37,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.7299120426177979\n"]},{"output_type":"stream","name":"stderr","text":["7501it [40:19,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.9911496043205261\n"]},{"output_type":"stream","name":"stderr","text":["8001it [43:00,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  1.146252989768982\n"]},{"output_type":"stream","name":"stderr","text":["8501it [45:41,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.9517243504524231\n"]},{"output_type":"stream","name":"stderr","text":["9001it [48:23,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.7559008598327637\n"]},{"output_type":"stream","name":"stderr","text":["9501it [51:04,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Loss:  0.9773476719856262\n"]},{"output_type":"stream","name":"stderr","text":["10000it [53:45,  3.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.3605775535106659\n"]},{"output_type":"stream","name":"stderr","text":["501it [02:41,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.5640197992324829\n"]},{"output_type":"stream","name":"stderr","text":["1001it [05:23,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.26062577962875366\n"]},{"output_type":"stream","name":"stderr","text":["1501it [08:06,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.339300274848938\n"]},{"output_type":"stream","name":"stderr","text":["2001it [10:48,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.3756526708602905\n"]},{"output_type":"stream","name":"stderr","text":["2501it [13:30,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.6659833788871765\n"]},{"output_type":"stream","name":"stderr","text":["3001it [16:13,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.4425959587097168\n"]},{"output_type":"stream","name":"stderr","text":["3501it [18:55,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.694567084312439\n"]},{"output_type":"stream","name":"stderr","text":["4001it [21:37,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.6522959470748901\n"]},{"output_type":"stream","name":"stderr","text":["4501it [24:19,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.16495603322982788\n"]},{"output_type":"stream","name":"stderr","text":["5001it [27:00,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.3164242208003998\n"]},{"output_type":"stream","name":"stderr","text":["5501it [29:42,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.7317782640457153\n"]},{"output_type":"stream","name":"stderr","text":["6001it [32:24,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.4293503761291504\n"]},{"output_type":"stream","name":"stderr","text":["6501it [35:05,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.42014145851135254\n"]},{"output_type":"stream","name":"stderr","text":["7001it [37:47,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.34518885612487793\n"]},{"output_type":"stream","name":"stderr","text":["7501it [40:29,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.7131802439689636\n"]},{"output_type":"stream","name":"stderr","text":["8001it [43:11,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.4182532727718353\n"]},{"output_type":"stream","name":"stderr","text":["8501it [45:54,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.5940449237823486\n"]},{"output_type":"stream","name":"stderr","text":["9001it [48:36,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.4114009439945221\n"]},{"output_type":"stream","name":"stderr","text":["9501it [51:18,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Loss:  0.5195344686508179\n"]},{"output_type":"stream","name":"stderr","text":["10000it [53:59,  3.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.23858198523521423\n"]},{"output_type":"stream","name":"stderr","text":["501it [02:42,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.288318395614624\n"]},{"output_type":"stream","name":"stderr","text":["1001it [05:24,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.28300678730010986\n"]},{"output_type":"stream","name":"stderr","text":["1501it [08:06,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.5352029204368591\n"]},{"output_type":"stream","name":"stderr","text":["2001it [10:47,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.39570027589797974\n"]},{"output_type":"stream","name":"stderr","text":["2501it [13:30,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.20877932012081146\n"]},{"output_type":"stream","name":"stderr","text":["3001it [16:12,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.11388449370861053\n"]},{"output_type":"stream","name":"stderr","text":["3501it [18:54,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.44175994396209717\n"]},{"output_type":"stream","name":"stderr","text":["4001it [21:36,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.2436343878507614\n"]},{"output_type":"stream","name":"stderr","text":["4501it [24:18,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.13846834003925323\n"]},{"output_type":"stream","name":"stderr","text":["5001it [27:00,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.3464856743812561\n"]},{"output_type":"stream","name":"stderr","text":["5501it [29:42,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.4413711428642273\n"]},{"output_type":"stream","name":"stderr","text":["6001it [32:24,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.17848870158195496\n"]},{"output_type":"stream","name":"stderr","text":["6501it [35:07,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.34187203645706177\n"]},{"output_type":"stream","name":"stderr","text":["7001it [37:48,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.2690199017524719\n"]},{"output_type":"stream","name":"stderr","text":["7501it [40:30,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.32926705479621887\n"]},{"output_type":"stream","name":"stderr","text":["8001it [43:11,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.2855290174484253\n"]},{"output_type":"stream","name":"stderr","text":["8501it [45:53,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.2446592003107071\n"]},{"output_type":"stream","name":"stderr","text":["9001it [48:35,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.17853926122188568\n"]},{"output_type":"stream","name":"stderr","text":["9501it [51:17,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Loss:  0.32777485251426697\n"]},{"output_type":"stream","name":"stderr","text":["10000it [53:58,  3.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.13067609071731567\n"]},{"output_type":"stream","name":"stderr","text":["501it [02:41,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.17755278944969177\n"]},{"output_type":"stream","name":"stderr","text":["1001it [05:23,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.16327454149723053\n"]},{"output_type":"stream","name":"stderr","text":["1501it [08:04,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.18624018132686615\n"]},{"output_type":"stream","name":"stderr","text":["2001it [10:46,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.27503716945648193\n"]},{"output_type":"stream","name":"stderr","text":["2501it [13:27,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.2050362229347229\n"]},{"output_type":"stream","name":"stderr","text":["3001it [16:09,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.10061881691217422\n"]},{"output_type":"stream","name":"stderr","text":["3501it [18:51,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.18972863256931305\n"]},{"output_type":"stream","name":"stderr","text":["4001it [21:33,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.22989068925380707\n"]},{"output_type":"stream","name":"stderr","text":["4501it [24:15,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.15245027840137482\n"]},{"output_type":"stream","name":"stderr","text":["5001it [26:57,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.2383115589618683\n"]},{"output_type":"stream","name":"stderr","text":["5501it [29:39,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.30992311239242554\n"]},{"output_type":"stream","name":"stderr","text":["6001it [32:20,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.23784184455871582\n"]},{"output_type":"stream","name":"stderr","text":["6501it [35:02,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.13927870988845825\n"]},{"output_type":"stream","name":"stderr","text":["7001it [37:44,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.2330712527036667\n"]},{"output_type":"stream","name":"stderr","text":["7501it [40:25,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.5202247500419617\n"]},{"output_type":"stream","name":"stderr","text":["8001it [43:07,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.38418900966644287\n"]},{"output_type":"stream","name":"stderr","text":["8501it [45:49,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.33580875396728516\n"]},{"output_type":"stream","name":"stderr","text":["9001it [48:30,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.313263475894928\n"]},{"output_type":"stream","name":"stderr","text":["9501it [51:12,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Loss:  0.2503328025341034\n"]},{"output_type":"stream","name":"stderr","text":["10000it [53:53,  3.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.06323497742414474\n"]},{"output_type":"stream","name":"stderr","text":["501it [02:41,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.18474550545215607\n"]},{"output_type":"stream","name":"stderr","text":["1001it [05:23,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.24723979830741882\n"]},{"output_type":"stream","name":"stderr","text":["1501it [08:05,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.19665253162384033\n"]},{"output_type":"stream","name":"stderr","text":["2001it [10:47,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.1612863838672638\n"]},{"output_type":"stream","name":"stderr","text":["2501it [13:29,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.3297800123691559\n"]},{"output_type":"stream","name":"stderr","text":["3001it [16:11,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.13801857829093933\n"]},{"output_type":"stream","name":"stderr","text":["3501it [18:52,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.20286692678928375\n"]},{"output_type":"stream","name":"stderr","text":["4001it [21:34,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.2172744870185852\n"]},{"output_type":"stream","name":"stderr","text":["4501it [24:16,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.09871134161949158\n"]},{"output_type":"stream","name":"stderr","text":["5001it [26:57,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.18432378768920898\n"]},{"output_type":"stream","name":"stderr","text":["5501it [29:39,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.2475298047065735\n"]},{"output_type":"stream","name":"stderr","text":["6001it [32:21,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.20866423845291138\n"]},{"output_type":"stream","name":"stderr","text":["6501it [35:03,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.41631579399108887\n"]},{"output_type":"stream","name":"stderr","text":["7001it [37:45,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.25881996750831604\n"]},{"output_type":"stream","name":"stderr","text":["7501it [40:27,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.23751187324523926\n"]},{"output_type":"stream","name":"stderr","text":["8001it [43:08,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.3495353162288666\n"]},{"output_type":"stream","name":"stderr","text":["8501it [45:50,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.11837420612573624\n"]},{"output_type":"stream","name":"stderr","text":["9001it [48:32,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.2312224954366684\n"]},{"output_type":"stream","name":"stderr","text":["9501it [51:14,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Loss:  0.5611686706542969\n"]},{"output_type":"stream","name":"stderr","text":["10000it [53:55,  3.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.2268880009651184\n"]},{"output_type":"stream","name":"stderr","text":["501it [02:42,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.10646704584360123\n"]},{"output_type":"stream","name":"stderr","text":["1001it [05:23,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.10745353996753693\n"]},{"output_type":"stream","name":"stderr","text":["1501it [08:05,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.19618254899978638\n"]},{"output_type":"stream","name":"stderr","text":["2001it [10:47,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.10223693400621414\n"]},{"output_type":"stream","name":"stderr","text":["2501it [13:29,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.14994823932647705\n"]},{"output_type":"stream","name":"stderr","text":["3001it [16:11,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.1705457717180252\n"]},{"output_type":"stream","name":"stderr","text":["3501it [18:52,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.07993350178003311\n"]},{"output_type":"stream","name":"stderr","text":["4001it [21:34,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.14902395009994507\n"]},{"output_type":"stream","name":"stderr","text":["4501it [24:16,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.19873274862766266\n"]},{"output_type":"stream","name":"stderr","text":["5001it [26:58,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.11925888061523438\n"]},{"output_type":"stream","name":"stderr","text":["5501it [29:40,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.2237645536661148\n"]},{"output_type":"stream","name":"stderr","text":["6001it [32:22,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.15259405970573425\n"]},{"output_type":"stream","name":"stderr","text":["6501it [35:04,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.19642768800258636\n"]},{"output_type":"stream","name":"stderr","text":["7001it [37:46,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.030064236372709274\n"]},{"output_type":"stream","name":"stderr","text":["7501it [40:28,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.1406635046005249\n"]},{"output_type":"stream","name":"stderr","text":["8001it [43:10,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.23911349475383759\n"]},{"output_type":"stream","name":"stderr","text":["8501it [45:53,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.1256907880306244\n"]},{"output_type":"stream","name":"stderr","text":["9001it [48:35,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.16528479754924774\n"]},{"output_type":"stream","name":"stderr","text":["9501it [51:17,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Loss:  0.23574624955654144\n"]},{"output_type":"stream","name":"stderr","text":["10000it [53:58,  3.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.10155382752418518\n"]},{"output_type":"stream","name":"stderr","text":["501it [02:42,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.059308670461177826\n"]},{"output_type":"stream","name":"stderr","text":["1001it [05:24,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.1350003033876419\n"]},{"output_type":"stream","name":"stderr","text":["1501it [08:06,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.152059406042099\n"]},{"output_type":"stream","name":"stderr","text":["2001it [10:48,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.094746433198452\n"]},{"output_type":"stream","name":"stderr","text":["2501it [13:30,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.10763178020715714\n"]},{"output_type":"stream","name":"stderr","text":["3001it [16:12,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.14226730167865753\n"]},{"output_type":"stream","name":"stderr","text":["3501it [18:54,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.18601493537425995\n"]},{"output_type":"stream","name":"stderr","text":["4001it [21:37,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.09247372299432755\n"]},{"output_type":"stream","name":"stderr","text":["4501it [24:19,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.16461242735385895\n"]},{"output_type":"stream","name":"stderr","text":["5001it [27:02,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.14926908910274506\n"]},{"output_type":"stream","name":"stderr","text":["5501it [29:45,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.09251000732183456\n"]},{"output_type":"stream","name":"stderr","text":["6001it [32:27,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.12867522239685059\n"]},{"output_type":"stream","name":"stderr","text":["6501it [35:10,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.4345528185367584\n"]},{"output_type":"stream","name":"stderr","text":["7001it [37:52,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.159502312541008\n"]},{"output_type":"stream","name":"stderr","text":["7501it [40:34,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.17095375061035156\n"]},{"output_type":"stream","name":"stderr","text":["8001it [43:16,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.4262681007385254\n"]},{"output_type":"stream","name":"stderr","text":["8501it [45:58,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.15780547261238098\n"]},{"output_type":"stream","name":"stderr","text":["9001it [48:39,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.1281372308731079\n"]},{"output_type":"stream","name":"stderr","text":["9501it [51:21,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Loss:  0.475948691368103\n"]},{"output_type":"stream","name":"stderr","text":["10000it [54:02,  3.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.07828802615404129\n"]},{"output_type":"stream","name":"stderr","text":["501it [02:42,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.02017185464501381\n"]},{"output_type":"stream","name":"stderr","text":["1001it [05:23,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.13743939995765686\n"]},{"output_type":"stream","name":"stderr","text":["1501it [08:05,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.14084237813949585\n"]},{"output_type":"stream","name":"stderr","text":["2001it [10:47,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.10052508860826492\n"]},{"output_type":"stream","name":"stderr","text":["2501it [13:29,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.1319633275270462\n"]},{"output_type":"stream","name":"stderr","text":["3001it [16:11,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.19085103273391724\n"]},{"output_type":"stream","name":"stderr","text":["3501it [18:52,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.12215378135442734\n"]},{"output_type":"stream","name":"stderr","text":["4001it [21:34,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.03993399441242218\n"]},{"output_type":"stream","name":"stderr","text":["4501it [24:16,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.1951676905155182\n"]},{"output_type":"stream","name":"stderr","text":["5001it [26:57,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.14986185729503632\n"]},{"output_type":"stream","name":"stderr","text":["5501it [29:39,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.09601689875125885\n"]},{"output_type":"stream","name":"stderr","text":["6001it [32:21,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.1507376879453659\n"]},{"output_type":"stream","name":"stderr","text":["6501it [35:03,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.32666507363319397\n"]},{"output_type":"stream","name":"stderr","text":["7001it [37:44,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.21476277709007263\n"]},{"output_type":"stream","name":"stderr","text":["7501it [40:26,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.22312003374099731\n"]},{"output_type":"stream","name":"stderr","text":["8001it [43:08,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.09912538528442383\n"]},{"output_type":"stream","name":"stderr","text":["8501it [45:50,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.14009538292884827\n"]},{"output_type":"stream","name":"stderr","text":["9001it [48:32,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.31814828515052795\n"]},{"output_type":"stream","name":"stderr","text":["9501it [51:15,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Loss:  0.11616554856300354\n"]},{"output_type":"stream","name":"stderr","text":["10000it [53:57,  3.09it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"9MZV-HoIsTdj","executionInfo":{"status":"ok","timestamp":1638630574296,"user_tz":-540,"elapsed":27313,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}}},"source":["# model save\n","tokenizer.save_pretrained('/content/drive/MyDrive/cakd3_colab/3차 프로젝트/Etri_et5/Etri_et5_model_save/Etri_et5_model_save_(290000*10)_extra')\n","model.save_pretrained('/content/drive/MyDrive/cakd3_colab/3차 프로젝트/Etri_et5/Etri_et5_model_save/Etri_et5_model_save_(290000*10)_extra')"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YgKeh3JpjPF-"},"source":["Validation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"h0ly0z2xsSwq","executionInfo":{"status":"ok","timestamp":1638725623166,"user_tz":-540,"elapsed":8512520,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}},"outputId":"a8982f28-baa4-46d3-8f6d-97d1bd1415e8"},"source":["\n","\n","validation_dataset.columns = ['ctext','text']\n","validation_dataset.ctext = 'summarize: ' + validation_dataset.ctext\n","\n","val_set = CustomDataset(validation_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","\n","val_loader = DataLoader(val_set, **val_params)\n","\n","for epoch in range(config.VAL_EPOCHS):\n","    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n","    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n","\n","final_df"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Completed 0\n","Completed 100\n","Completed 200\n","Completed 300\n","Completed 400\n","Completed 500\n","Completed 600\n","Completed 700\n","Completed 800\n","Completed 900\n","Completed 1000\n","Completed 1100\n","Completed 1200\n","Completed 1300\n","Completed 1400\n","Completed 1500\n","Completed 1600\n","Completed 1700\n","Completed 1800\n","Completed 1900\n","Completed 2000\n","Completed 2100\n","Completed 2200\n","Completed 2300\n","Completed 2400\n","Completed 2500\n","Completed 2600\n","Completed 2700\n","Completed 2800\n","Completed 2900\n","Completed 3000\n","Completed 3100\n","Completed 3200\n","Completed 3300\n","Completed 3400\n","Completed 3500\n","Completed 3600\n","Completed 3700\n","Completed 3800\n","Completed 3900\n","Completed 4000\n","Completed 4100\n","Completed 4200\n","Completed 4300\n","Completed 4400\n","Completed 4500\n","Completed 4600\n","Completed 4700\n","Completed 4800\n","Completed 4900\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Generated Text</th>\n","      <th>Actual Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>의 메카 충북 단양군에서 탁구인들이 그동안 갈고 3 % 이상 날에 전국 탁구인들을 ...</td>\n","      <td>9~10일 이틀간 충북 단양국민체육센터에서 '제3회 만천하스카이워크배 전국오픈 탁구...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>미세먼지 저감을 위해 시행 중인 차량운행제한 정책의 실효성을 높이기 위해 서울시가 ...</td>\n","      <td>'승용차마일리지제'는 서울시가 지난 2017년 도입한 것으로, 미세먼지 저감을 위한...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>의 감각기관에 미세한 전기를 흘려보내 운영하고 일정 구역에 부표를 설치하는 방식으로...</td>\n","      <td>최근 제주도내 해수욕장에서 발생한 상어 출현으로, 제주특별자치도는 10일 상어퇴치기...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>전 대표가 패스트트랙 법안을 본회의에 부의하려는 것을 두고 페이스북을 통해 “문 의...</td>\n","      <td>지난달 30일 홍준표 자유한국당 전 대표가 문희상 의장이 패스트트랙 법안을 본회의에...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>·스마트물류 시장 개척을 위해 삼성SDS가 25일 서울 송파구 본사에서 중국 IT서...</td>\n","      <td>삼성SDS(대표 홍원표)는 지난 25일 서울 송파구 본사에서 시스템통합, IT아웃소...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>배터리 분야 등 전문 인력 확보에 SK이노베이션 총괄 사장의 인재 영입 철학을 엿볼...</td>\n","      <td>SK이노베이션은 김준 SK이노베이션 총괄 사장의 인재 영입 철학을 반영하여 작년 4...</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>좋은 취업상담 프로그램인 '상상 커리어이닝'은 KT&amp;G가 대학생들을 위해 개발한 취...</td>\n","      <td>내달 7일까지 KT&amp;G는 2~4학년 대학생 150명을 대상으로 취업 상담 프로그램 ...</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>의 주방점검 결과 '보리밥&amp;코다리찜'집의 주방점검이 분당 최고 시청률 8.9%로 동...</td>\n","      <td>지난 27일 '백종원의 골목식당'은 '보리밥&amp;코다리찜'의 주방점검 장면에서 동시간대...</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>에게 수능 당일 가족들이 꼭 챙겨주는 채소품 중 하나가 우황청심원( '마음을 맑게 ...</td>\n","      <td>소의 도축 과정에서 발견하여 약재로 쓰는 우황은 기본적으로 몸 안의 열을 치료하는 ...</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>천정배 의원은 24일 국가보훈처로부터 헌정질서파괴범인 전두환 전 대통령은 사망할 경...</td>\n","      <td>국가보훈처는 전두환 전 대통령이 사망하는 경우에도 전과사실이 실효되지 않아 국립묘지...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                         Generated Text                                        Actual Text\n","0     의 메카 충북 단양군에서 탁구인들이 그동안 갈고 3 % 이상 날에 전국 탁구인들을 ...  9~10일 이틀간 충북 단양국민체육센터에서 '제3회 만천하스카이워크배 전국오픈 탁구...\n","1     미세먼지 저감을 위해 시행 중인 차량운행제한 정책의 실효성을 높이기 위해 서울시가 ...  '승용차마일리지제'는 서울시가 지난 2017년 도입한 것으로, 미세먼지 저감을 위한...\n","2     의 감각기관에 미세한 전기를 흘려보내 운영하고 일정 구역에 부표를 설치하는 방식으로...  최근 제주도내 해수욕장에서 발생한 상어 출현으로, 제주특별자치도는 10일 상어퇴치기...\n","3     전 대표가 패스트트랙 법안을 본회의에 부의하려는 것을 두고 페이스북을 통해 “문 의...  지난달 30일 홍준표 자유한국당 전 대표가 문희상 의장이 패스트트랙 법안을 본회의에...\n","4     ·스마트물류 시장 개척을 위해 삼성SDS가 25일 서울 송파구 본사에서 중국 IT서...  삼성SDS(대표 홍원표)는 지난 25일 서울 송파구 본사에서 시스템통합, IT아웃소...\n","...                                                 ...                                                ...\n","9995  배터리 분야 등 전문 인력 확보에 SK이노베이션 총괄 사장의 인재 영입 철학을 엿볼...  SK이노베이션은 김준 SK이노베이션 총괄 사장의 인재 영입 철학을 반영하여 작년 4...\n","9996  좋은 취업상담 프로그램인 '상상 커리어이닝'은 KT&G가 대학생들을 위해 개발한 취...  내달 7일까지 KT&G는 2~4학년 대학생 150명을 대상으로 취업 상담 프로그램 ...\n","9997  의 주방점검 결과 '보리밥&코다리찜'집의 주방점검이 분당 최고 시청률 8.9%로 동...  지난 27일 '백종원의 골목식당'은 '보리밥&코다리찜'의 주방점검 장면에서 동시간대...\n","9998  에게 수능 당일 가족들이 꼭 챙겨주는 채소품 중 하나가 우황청심원( '마음을 맑게 ...  소의 도축 과정에서 발견하여 약재로 쓰는 우황은 기본적으로 몸 안의 열을 치료하는 ...\n","9999  천정배 의원은 24일 국가보훈처로부터 헌정질서파괴범인 전두환 전 대통령은 사망할 경...  국가보훈처는 전두환 전 대통령이 사망하는 경우에도 전과사실이 실효되지 않아 국립묘지...\n","\n","[10000 rows x 2 columns]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"DuOAdekCQxTi","executionInfo":{"status":"ok","timestamp":1638725623167,"user_tz":-540,"elapsed":9,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}}},"source":["final_df.to_csv('/content/drive/MyDrive/cakd3_colab/3차 프로젝트/final_df/etri_et5_(290000*10)_extra.csv')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"SvJw3yy4AqIk","executionInfo":{"status":"ok","timestamp":1638725623167,"user_tz":-540,"elapsed":8,"user":{"displayName":"배송이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09026086329429757557"}},"outputId":"58bc891e-11db-480d-d294-6b64036b1570"},"source":["final_df['Generated Text'][4]"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'·스마트물류 시장 개척을 위해 삼성SDS가 25일 서울 송파구 본사에서 중국 IT서비스 기업 디지털차이나와 사업협력 MOU를 체결하고 혁신 기술과 솔루션을 제공하기로 했다.'"]},"metadata":{},"execution_count":14}]}]}